{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worldwide-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%save Apprentissage_par_corpus.py 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "previous-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, json\n",
    "from pathlib import Path\n",
    "from Embedding import Embedding\n",
    "\n",
    "class Apprentissage_par_corpus(Embedding) :\n",
    "    \n",
    "    def __init__ (self, arg) :\n",
    "        \n",
    "        # init embedding\n",
    "        super().__init__ (arg)\n",
    "        \n",
    "        # echantillonnage\n",
    "        nombre_ID = arg ['nombre_ID']\n",
    "        nombre_ID_pour_apprentissage = arg ['pathDico_systeme'] ['calcul'] ['nombre_ID_pour_apprentissage']\n",
    "        \n",
    "        if nombre_ID < nombre_ID_pour_apprentissage :\n",
    "            self.pourcentage_echantillon = 101. # toojours vrai\n",
    "        else:\n",
    "            self.pourcentage_echantillon = float (nombre_ID) / float (nombre_ID_pour_apprentissage)\n",
    "        \n",
    "        \n",
    "        # path corpus \n",
    "        self.path_corpus = arg ['Path_corpus']\n",
    "        \n",
    "        \n",
    "    def init_corpus (self, ) :\n",
    "        self.f_corpus = open (self.path_corpus, 'w')\n",
    "        return\n",
    "            \n",
    "            \n",
    "    def ecrire_luigi_file_random(self, fin) :\n",
    "        pourcentage_echantillon = self.pourcentage_echantillon      \n",
    "        for ligne_json in fin:\n",
    "            x = random.uniform (0., 100.)\n",
    "            if  x < pourcentage_echantillon :\n",
    "                dico_ligne = json.loads (ligne_json)\n",
    "                liste_mot = [v for v in dico_ligne.values()] [0]\n",
    "                liste_mot.append('\\n')\n",
    "                ligne =  ' '.join (liste_mot)\n",
    "                \n",
    "                self.f_corpus.write(ligne )\n",
    "                continue\n",
    "            fin.close()\n",
    "            continue\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def Apprentissage_par_corpus(self,) :\n",
    "        self.f_corpus.close()\n",
    "        if Path(self.path_corpus).stat().st_size != 0 :\n",
    "            self.apprentissage  (self.path_corpus, isDocument = False)\n",
    "        return\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-aerospace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vertical-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apprentissage modele par corpus en temps = 0.11866998672485352\n",
      "\n",
      "apprentissage modele par corpus avec repetition  200  et un temps = 17.077282905578613\n",
      "\n",
      "similarite entre deux paragraphes calculés differents = -0.18584098\n",
      "distance entre deux paragraphes calculés differents = 1.5400267\n",
      "\n",
      "conclusion : OK pour l inference \n",
      "end of job\n"
     ]
    }
   ],
   "source": [
    "import json, sys, os, time\n",
    "import numpy as np\n",
    "\n",
    "from gensim.utils import save_as_line_sentence\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "path = \"../outils\"\n",
    "if path not in sys.path : \n",
    "    sys.path.append (path)\n",
    "from Entree_sortie_lock import Entree_sortie_lock\n",
    "    \n",
    "from Kernel_BE import Kernel\n",
    "\n",
    "from Embedding import Gestion_vecteur, Embedding\n",
    "from Apprentissage_par_corpus import Apprentissage_par_corpus\n",
    "\n",
    "\n",
    "\n",
    "arg = {}\n",
    "\n",
    "nom_environnement = 'test'\n",
    "arg ['nom_environnement'] =  nom_environnement\n",
    "\n",
    "\n",
    "pathFile_evenements = '/dico_evenements_2.json'\n",
    "pathFile_systeme = '/dico_systeme_2.json'\n",
    "\n",
    "arg_entree_sortie_lock = {} \n",
    "arg_entree_sortie_lock ['nom_environnement'] = nom_environnement\n",
    "arg_entree_sortie_lock['pathFile'] = pathFile_evenements\n",
    "Entree_sortie_evenements = Entree_sortie_lock (arg_entree_sortie_lock)\n",
    "dico_evenements, etat = Entree_sortie_evenements.lire()\n",
    "arg ['pathDico_evenements'] = dico_evenements\n",
    "\n",
    "arg_entree_sortie_lock ['pathFile'] = pathFile_systeme\n",
    "Entree_sortie_systeme = Entree_sortie_lock (arg_entree_sortie_lock)\n",
    "dico_systeme, etat = Entree_sortie_systeme.lire()\n",
    "arg ['pathDico_systeme'] = dico_systeme\n",
    "\n",
    "pas = 'semaine'\n",
    "pas_date = '2021-02-08 00:00:00.000000'.replace (':', '.').replace (' ', '_')\n",
    "arg ['pathLuigi_file'] = '../data/test/data/'+ pas + '/' + pas_date + '/'\n",
    "\n",
    "arg ['pathLuigi_file'] = './'\n",
    "\n",
    "arg['pathModele'] = '../data/test/data/'+ pas + '/' +'Modele_test2.model'\n",
    "arg ['Path_corpus'] = 'mon_corpus.txt'\n",
    "\n",
    "\n",
    "arg ['Path_corpus']  = 'mon_corpus.txt'\n",
    "\n",
    "\n",
    "pathFile = './test_embedding.json'\n",
    "fin = open (pathFile,'r')\n",
    "\n",
    "dico = {}\n",
    "for ligne_json in fin:\n",
    "    dico_ligne = json.loads (ligne_json)\n",
    "    dico.update(dico_ligne)\n",
    "    \n",
    "liste_ID = [ID for ID in dico.keys()]\n",
    "liste_ID.sort()\n",
    "arg ['nombre_ID'] = len(liste_ID)\n",
    "\n",
    "\n",
    "A = Apprentissage_par_corpus(arg)\n",
    "\n",
    "\n",
    "pathFile = './test_embedding.json'\n",
    "fin = open (pathFile,'r')\n",
    "\n",
    "t = time.time()\n",
    "A.init_corpus ()\n",
    "A.ecrire_luigi_file_random (fin)\n",
    "A.Apprentissage_par_corpus ()\n",
    "A.save_model ()\n",
    "delaie = time.time() - t\n",
    "\n",
    "print (\"apprentissage modele par corpus en temps =\", delaie)\n",
    "print ()\n",
    "\n",
    "\n",
    "\n",
    "# on repete \n",
    "repetition = 200\n",
    "\n",
    "A = Apprentissage_par_corpus(arg)\n",
    "\n",
    "\n",
    "pathFile = './test_embedding.json'\n",
    "fin = open (pathFile,'r')\n",
    "\n",
    "t = time.time()\n",
    "A.init_corpus ()\n",
    "A.ecrire_luigi_file_random (fin)\n",
    "for _ in range (0, repetition) :\n",
    "    A.Apprentissage_par_corpus ()\n",
    "A.save_model ()\n",
    "delaie = time.time() - t\n",
    "\n",
    "print (\"apprentissage modele par corpus avec repetition \", repetition, ' et un temps =', delaie)\n",
    "print ()\n",
    "\n",
    "# on test la qualité\n",
    "E = Gestion_vecteur (arg)\n",
    "\n",
    "pathFile = './test_embedding.json'\n",
    "fin = open (pathFile,'r')\n",
    "        \n",
    "dico = {}\n",
    "for ligne_json in fin:\n",
    "    dico_ligne = json.loads (ligne_json)\n",
    "    dico.update(dico_ligne)\n",
    "    \n",
    "liste_ID = [ID for ID in dico.keys()]\n",
    "liste_ID.sort()\n",
    "\n",
    "\n",
    "ID_1 = liste_ID [0]\n",
    "paragraphe_1 = dico [ID_1]\n",
    "vecteur_calcule_1 = E.infer_vecteur_embedding (paragraphe_1)\n",
    "\n",
    "ID_2 = liste_ID [len(liste_ID) - 1]\n",
    "paragraphe_2 = dico [ID_2]\n",
    "vecteur_calcule_2 = E.infer_vecteur_embedding (paragraphe_2)\n",
    "\n",
    "similarite1_1 = E.similarite_par_vecteur (vecteur_calcule_1, vecteur_calcule_2)\n",
    "print ('similarite entre deux paragraphes calculés differents =', similarite1_1 )\n",
    "distance_1_1 = E.calcul_distance (vecteur_calcule_1 ,vecteur_calcule_2)\n",
    "print ('distance entre deux paragraphes calculés differents =', distance_1_1)\n",
    "print ()\n",
    "\n",
    "\n",
    "print ('conclusion : OK pour l inference ')\n",
    "\n",
    "normalized_array, liste_ID = E.get_vecteur_normalized (dico)\n",
    "\n",
    "ID_0 = liste_ID [0]\n",
    "paragraphe = dico [ID_0]\n",
    "\n",
    "v0 = E.infer_vecteur_embedding (paragraphe)\n",
    "v0_0 = v0/np.linalg.norm(v0)\n",
    "\n",
    "assert (np.sum(normalized_array [0, :] - v0_0) < 10.e-7)\n",
    "\n",
    "print ('end of job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "special-trademark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-reminder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
