{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%save Kernel_BE.py 4\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### coding: utf-8\n",
    "import bz2 \n",
    "import lzma\n",
    "import gzip \n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "from elasticsearch import Elasticsearch \n",
    "from elasticsearch.connection import Urllib3HttpConnection\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "class rien () :\n",
    "    def compress (self, x) :\n",
    "        return x\n",
    "    def decompress (self, x) :\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Kernel () :\n",
    "    def __init__ ( self, dico, dispersion = 1000000) :\n",
    "        '''\n",
    "        \n",
    "                  createur = \"generic\", \n",
    "                  date_emetteur = datetime.now(),\n",
    "                  http_auth = None,\n",
    "                  timeout=10,\n",
    "                  host = \"localhost\", \n",
    "                  port = 9200 ,\n",
    "                  zipChoisi = 'bz2',\n",
    "                  index_log_error = \"trace1\",\n",
    "                  index_log_warning = \"trace2\",\n",
    "                  index_log_trace = \"trace3\",\n",
    "                  index_system = \"systeme\",\n",
    "                  isPurge_existing_index_log = True,\n",
    "                  extra_elasticsearch_args = None,\n",
    "                  trace = False,\n",
    "                  FF\n",
    "        \n",
    "        ######### centralise les I/O #########\n",
    "        en entree \n",
    "        le createur du process (esemble de taches) \n",
    "        la date de lancement par defaut ce jour\n",
    "        \n",
    "        ensuite\n",
    "        pour elastic : host, port\n",
    "        pour le zip : le choix par nom if none on ne fait rien,\n",
    "        \n",
    "        ensuite pour debug la trace (log elastic)\n",
    "        '''\n",
    "        self.dispersion = int(dispersion)\n",
    "        \n",
    "        self.createur = dico [\"createur\"]\n",
    "        date_emetteur = dico [\"date_emetteur\"]\n",
    "        http_auth = dico [\"hfrom Entree_sortie_lock import Entree_sortie_lockttp_auth\"]\n",
    "        timeout = dico [\"timeout\"]\n",
    "        host = dico [\"host\"]\n",
    "        port = dico [\"port\"]\n",
    "        zipChoisi = dico [\"zipChoisi\"]\n",
    "        index_log_error = dico [\"index_log_error\"]\n",
    "        index_log_warning = dico [\"index_log_warning\"]\n",
    "        index_log_trace = dico [\"index_log_trace\"]\n",
    "        index_system = dico [\"index_system\"]\n",
    "        isPurge_existing_index_log = dico [\"isPurge_existing_index_log\"]\n",
    "        extra_elasticsearch_args = dico [\"extra_elasticsearch_args\"]\n",
    "        trace = dico [\"trace\"]\n",
    "        #modif ##########################################\"\n",
    "        self.ID_reference_base = dico [\"ID_reference_base\"]\n",
    "        \n",
    "        self.lecture_evenements = \"../data/generation/evenements1.txt\" # modif client dico ['lecture_evenements']\n",
    "        \n",
    "        \n",
    "        self.date_emetteur = date_emetteur\n",
    "        self.trace = trace\n",
    "        \n",
    "        self.index_log_error = index_log_error\n",
    "        self.index_log_warning = index_log_warning\n",
    "        self.index_log_trace = index_log_trace\n",
    "        self.isPurge_existing_index_log = isPurge_existing_index_log\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.http_auth = http_auth\n",
    "        self.timeout = timeout\n",
    "        \n",
    "        if extra_elasticsearch_args is None:\n",
    "            extra_elasticsearch_args = {}\n",
    "        self.extra_elasticsearch_args = extra_elasticsearch_args\n",
    "         \n",
    "        \n",
    "        self.es = Elasticsearch(\n",
    "                        connection_class = Urllib3HttpConnection, # fonction externe\n",
    "                        host=self.host,\n",
    "                        port=self.port,\n",
    "                        http_auth=self.http_auth, # donne pour authentification\n",
    "                        timeout=self.timeout,\n",
    "                        **self.extra_elasticsearch_args,\n",
    "                        )\n",
    "        \n",
    "        \n",
    "        # init du system\n",
    "        self.index_system = index_system\n",
    "        index = index_system\n",
    "        if isPurge_existing_index_log or not self.es.indices.exists(index=index):\n",
    "            self.delete_index (index)\n",
    "            self.create_index (index)\n",
    "            # init date pour recuperer les logsdate = datetime.datetime.now() mis dans creationDoc\n",
    "            doc = self.creationDoc (\"systeme\", \"kernel\", \"init\",  \"pour recuperer les logs\",)\n",
    "            self.index_doc (doc, index, _id = 1 )\n",
    "        \n",
    "        # intialisation compression de données voir pb \"byte to string et inversement\"        \n",
    "        self.dicoZip = {'bz2' : bz2,\n",
    "                  'lzma' : lzma,\n",
    "                   'gzip' : gzip,\n",
    "                        }\n",
    "        self.initZip (zipChoisi = zipChoisi)\n",
    "        \n",
    "        \n",
    "        \n",
    "               \n",
    "        # pour la lemmatization       \n",
    "        \n",
    "        self.liste_type = ['NOM', 'AUX', 'VER', 'ADV', 'PRE', 'ADJ', 'ONO', 'CON',\n",
    "                  'ART:def', 'ADJ:ind', 'PRO:ind', 'PRO:int', 'PRO:rel',\n",
    "                  'ADJ:num', 'PRO:dem', 'ADJ:dem', 'PRO:per', 'ART:ind',\n",
    "                  'LIA', 'PRO:pos', 'ADJ:pos', '', 'ADJ:int']\n",
    "        \n",
    "        self.index_regroupement = \"regroupement\"\n",
    "        \n",
    "        self.settings_regroupement = { \"settings\" : {\n",
    "                                      'index.mapping.total_fields.limit':100000,\n",
    "                                     }\n",
    "        }\n",
    "        \n",
    "        self.dico_settings = {'regroupement' : self.settings_regroupement ,\n",
    "                             }\n",
    "                              \n",
    "                              \n",
    "        \n",
    "        self.structure_du_lexique = [\"1_ortho\" , \n",
    "                                     \"3_lemme\" , \n",
    "                                     \"4_cgram\" , \n",
    "                                     \"5_genre\" , \n",
    "                                     \"6_nombre\" , \n",
    "                                     \"7_freqlemfilms2\" , \n",
    "                                     \"8_freqlemlivres\" , \n",
    "                                     \"9_freqfilms2\" , \n",
    "                                     \"10_freqlivres\" , \n",
    "                                     \"11_infover\" , \n",
    "                                     \"12_nbhomogr\" , \n",
    "                                     \"13_nbhomoph\" , \n",
    "                                     \"14_islem\" , \n",
    "                                     \"15_nblettres\" , \n",
    "                                     \"19_voisorth\" , \n",
    "                                     \"21_puorth\" , \n",
    "                                     \"22_puphon\" , \n",
    "                                     \"29_cgramortho\" , \n",
    "                                     \"30_deflem\" , \n",
    "                                     \"31_defobs\" , \n",
    "                                     \"32_old20\" , \n",
    "                                     \"33_pld20\" , \n",
    "                                     \"35_nbmorph\" , \n",
    "                                    ]\n",
    "        \n",
    "\n",
    "        \n",
    "        self.debut_fichier_regroupement = \"../../../data/Lexique383_group\" # a voir\n",
    "        \n",
    "    @property\n",
    "    def raise_on_error(self):\n",
    "        \"\"\"\n",
    "        Renvoyer False pout permettre à l'appelant de gérer le log d'erreur\n",
    "        dans le cas du bulk\n",
    "        \"\"\"\n",
    "        return False\n",
    "    \n",
    "    @property\n",
    "    def mapping_log(self,) :\n",
    "        \"\"\"\n",
    "        Dictionary with custom mapping or `None`.\n",
    "        probleme avec Elastic sur le mapping ??????????\n",
    "        \"\"\"\n",
    "        return None\n",
    "        \n",
    "    @property\n",
    "    def mapping(self):\n",
    "        \"\"\"\n",
    "        Dictionary with custom mapping or `None`.\n",
    "        probleme avec Elastic sur le mapping ??????????\n",
    "        \"\"\"\n",
    "        mapping =  {\n",
    "                        \"properties\": {\n",
    "                            \"ID\": {\n",
    "                                \"type\": \"keyword\" # formerly \"string\"\n",
    "                            },\n",
    "                            \"ID_reference\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            },\n",
    "                            \"date_evenement\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            },\n",
    "                            \"nom_variable\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            },\n",
    "                            \"valeur\" : {\n",
    "                                \"type\" : \"keyword\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                \n",
    "        \n",
    "        return mapping\n",
    "    \n",
    "    @property\n",
    "    def mapping_vecteur(self):\n",
    "        \"\"\"\n",
    "        Dictionary with custom mapping or `None`.\n",
    "        \n",
    "        \"\"\"\n",
    "        mapping =  {\n",
    "                        \"properties\": {\n",
    "                            \"ID\": {\n",
    "                                \"type\": \"integer\" \n",
    "                            },\n",
    "                            \"ID_random\": {\n",
    "                                \"type\": \"integer\"\n",
    "                            },\n",
    "                            \"vecteur\": {\n",
    "                                \"type\": \"float\"\n",
    "                            },\n",
    "                            \"paragraphe\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                \n",
    "        \n",
    "        return mapping\n",
    "    \n",
    "    def liste2array(self, data,dtype = np.int32) :\n",
    "        return np.array(data, dtype = dtype)\n",
    "    \n",
    "    def array2liste (self,array,):\n",
    "        return array.tolist()\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "    def compression (self, data) :\n",
    "        return self.zip.compress (data)\n",
    "    \n",
    "    def decompression (self, dataCompresse) :\n",
    "        return self.zip.decompress (dataCompresse)\n",
    "    \n",
    "    def initZip (self, zipChoisi = None ) :\n",
    "        if zipChoisi is None :\n",
    "            self.zip = rien()\n",
    "        else:\n",
    "            self.zip = self.dicoZip[zipChoisi]\n",
    "            \n",
    "    def create_index(self, index):\n",
    "        \"\"\"\n",
    "        creation de l' index si il n'existe pas.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.es.indices.exists(index=index):\n",
    "            self.es.indices.create(index=index)\n",
    "            \n",
    "    def delete_index(self, index):\n",
    "        \"\"\"\n",
    "        Supprime l'index, si il existe.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.es.indices.exists(index=  index):\n",
    "            self.es.indices.delete(index = index)\n",
    "            \n",
    "    def _docs_vecteur (self, docIterator, index) :\n",
    "        dico = {'_index' : index, }\n",
    "        for doc in docIterator :\n",
    "            doc ['ID_random'] = randint (0,self.dispersion)\n",
    "            dico ['_source'] = doc\n",
    "            yield dico\n",
    "        return\n",
    "            \n",
    "    \n",
    "            \n",
    "    def _docs (self, docIterator, index) :\n",
    "        dico = {'_index' : index,}\n",
    "        for doc in docIterator :\n",
    "            dico ['_source'] = doc\n",
    "            yield dico\n",
    "        return\n",
    "    \n",
    "    def bulk_vecteur (self,\n",
    "                      docs,\n",
    "                      index,\n",
    "                      isPurge_existing_index = False,\n",
    "                      chunk_size = 2000,\n",
    "                     ):\n",
    "        \"\"\"\n",
    "        \n",
    "        docs est un iterateur comme son nom ne l'indique pas\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if isPurge_existing_index:\n",
    "            self.delete_index(index) # si existe detruit\n",
    "            \n",
    "        self.create_index(index) # si existe ne fait rien\n",
    "        \n",
    "        if not self.mapping_vecteur is None and isPurge_existing_index:\n",
    "                self.es.indices.put_mapping(index = index, body = self.mapping_vecteur)\n",
    "        \n",
    "        self.es.indices.put_settings({\"index\": {\"refresh_interval\": \"-1\"}},\n",
    "                                    index= index)\n",
    "\n",
    "        bulk(self.es, self._docs_vecteur (docs, index) , chunk_size = chunk_size,\n",
    "                  raise_on_error=self.raise_on_error) # en cas d'erreur on renvoie False\n",
    "\n",
    "        self.es.indices.put_settings({\"index\": {\"refresh_interval\": \"1s\"}},\n",
    "                                         index = index)\n",
    "        self.es.indices.refresh()\n",
    "        \n",
    "        return True # tout est OK\n",
    "    \n",
    "    \n",
    "       \n",
    "    def bulk (self, docs, index,\n",
    "              isPurge_existing_index = False,\n",
    "              chunk_size = 2000,\n",
    "             ):\n",
    "        \"\"\"\n",
    "        \n",
    "        docs est un iterateur comme son nom ne l'indique pas\n",
    "        \n",
    "        \"\"\"\n",
    "        mapping = self.mapping\n",
    "        #print (\"mapping =\", mapping)\n",
    "        \n",
    "        if isPurge_existing_index:\n",
    "            self.delete_index(index) # si existe detruit\n",
    "            \n",
    "        self.create_index(index) # si existe ne fait rien\n",
    "        \n",
    "        if not mapping is None and isPurge_existing_index:\n",
    "            #print (\"mapping =\", mapping)\n",
    "            self.es.indices.put_mapping(index = index, body = mapping)\n",
    "        \n",
    "        self.es.indices.put_settings({\"index\": {\"refresh_interval\": \"-1\"}},\n",
    "                                    index= index)\n",
    "\n",
    "        bulk(self.es, self._docs (docs, index) , chunk_size = chunk_size,\n",
    "                  raise_on_error=self.raise_on_error) # en cas d'erreur on renvoie False\n",
    "\n",
    "        self.es.indices.put_settings({\"index\": {\"refresh_interval\": \"1s\"}},\n",
    "                                         index = index)\n",
    "        self.es.indices.refresh()\n",
    "        \n",
    "        return True # tout est OK \n",
    "    \n",
    "    def count (self, index) :\n",
    "        if not self.es.indices.exists(index=  index):\n",
    "            return 0\n",
    "        \n",
    "        self.es.indices.refresh(index)\n",
    "        r = self.es.cat.count(index, params={\"format\": \"json\"})\n",
    "        return int (r [0] ['count'])\n",
    "    \n",
    "    # exemple de query sur les mots pour trouver les lemmes\n",
    "    def search_mot (self, index, mot, zone) :\n",
    "        self.es.indices.refresh (index)\n",
    "        query = {'query' : {'match' : {zone : mot}}}\n",
    "        #print (\"query =\", query )\n",
    "        res= self.es.search (index= index, body = query )\n",
    "        #res = self.elastic.search(index=index , body={\"query\": {\"match_all\": {}}})\n",
    "        #print ([hit['_source'] for hit in res ['hits'] ['hits']])\n",
    "        return [hit['_source'] for hit in res ['hits'] ['hits']]\n",
    "    \n",
    "    def creationDoc (self,origine, auteur, etape,  message,) :\n",
    "               \n",
    "        return {\"origine\": origine,\n",
    "               \"auteur\" : auteur,\n",
    "                \"etape\" : etape,\n",
    "                  \"date\" : datetime.now(),\n",
    "                   \"message\" : message, }\n",
    "        \n",
    "    \n",
    "    def log_error (self, auteur, etape,  message,) :\n",
    "        index = self.index_log_error\n",
    "        doc = self.creationDoc (\"error\", auteur, etape,  message,)\n",
    "        return self.index_doc (doc, index,)\n",
    "    \n",
    "    def log_warning (self, auteur, etape,  message,) :\n",
    "        index = self.index_log_warning\n",
    "        doc = self.creationDoc (\"warning\", auteur, etape,  message,)\n",
    "        return self.index_doc(doc, index,  )\n",
    "        \n",
    "    def log_trace (self, auteur, etape, message,  messagesStop = False) :\n",
    "        index = self.index_log_trace\n",
    "        doc = self.creationDoc (\"trace\", auteur, etape,  message,)\n",
    "        return self.index_doc (doc, index)\n",
    "        \n",
    "    def index_doc (self,doc, index, _id = None):\n",
    "        # on index l'erreur\n",
    "        if _id is None :\n",
    "            res = self.es.index (index = index, body = doc)\n",
    "        else :\n",
    "            res = self.es.index (index = index, id = _id, body = doc)\n",
    "        \n",
    "        self.es.indices.refresh()\n",
    "        #print ( \"dans ecriture erreur res =\", res['result'])\n",
    "        return True # tout est OK\n",
    "    \n",
    "    def get_date_system (self,) :\n",
    "        res = self.es.get(index=self.index_system, id=1)\n",
    "        doc = res['_source'] \n",
    "        return  doc ['date']\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_logs_error (self,) :\n",
    "        return self.get_logs(self.index_log_error)\n",
    "    def get_logs_warning (self,) :\n",
    "        return self.get_logs(self.index_log_warning)\n",
    "    def get_logs_trace(self,) :\n",
    "        return self.get_logs(self.index_log_trace)\n",
    "    \n",
    "    def get_logs (self, index, size = 10000) :\n",
    "        \n",
    "        self.es.indices.refresh (index)\n",
    "        \n",
    "        date_system = self.get_date_system ()\n",
    "        query = {'query' : {'range' : {\"date\": {\"gte\" : date_system}}} }\n",
    "        #print (\"query =\", query )\n",
    "        res= self.es.search (index= index, body = query,  size = size )\n",
    "        #res = self.elastic.search(index=index , body={\"query\": {\"match_all\": {}}})\n",
    "        #print ([hit['_source'] for hit in res ['hits'] ['hits']])\n",
    "        return [hit['_source'] for hit in res ['hits'] ['hits']]\n",
    "    \n",
    "    def calculRandom_vecteur (self, proportion, index,) :\n",
    "        \"\"\"\n",
    "        apres avoir randomiser la variable IDrandom (bulk_vecteur) entre 0 et self.dispersion\n",
    "        on calcul en fonction de la proportioon voulu des bornes inferieure et superieure\n",
    "        qui encadreront la recherche dans l-index qui contiend les vecteurs/paragraphes\n",
    "        \"\"\"\n",
    "                \n",
    "        nombreElements = self.count (index)\n",
    "        nombreElements_voulu = int ((proportion * nombreElements)/100.)\n",
    "        borne_inferieur_max = (nombreElements - nombreElements_voulu)\n",
    "        \n",
    "        borne_inferieur_random = randint (0, borne_inferieur_max)\n",
    "        borne_superieur = borne_inferieur_random + nombreElements_voulu\n",
    "        # en proportion\n",
    "        borne_inferieur_random = int((borne_inferieur_random*self.dispersion)/nombreElements)\n",
    "        borne_superieur = int((borne_superieur*self.dispersion)/nombreElements)\n",
    "        return borne_inferieur_random, borne_superieur\n",
    "        \n",
    "        \n",
    "    \n",
    "    def search_par_bloc_vecteur(self,\n",
    "                                 index,\n",
    "                                 isVecteur = True,\n",
    "                                 isParagraphe = False,\n",
    "                                 ID_random_min = 0,\n",
    "                                 ID_random_max = 0,\n",
    "                                 isRandom = True,\n",
    "\n",
    "                                 isID = False,\n",
    "                                 ID_min = \"\",\n",
    "                                 ID_max  = \"\",\n",
    "                                 ID_sort  = 'asc',\n",
    "                                 \n",
    "\n",
    "\n",
    "                                 size = 1000 ,\n",
    "\n",
    "                                ) :\n",
    "        \n",
    "        \n",
    "        _source = ['ID',]\n",
    "        if isVecteur: \n",
    "            _source .append( 'vecteur')\n",
    "        if isParagraphe :\n",
    "            _source.append('paragraphe')\n",
    "            \n",
    "                \n",
    "        \n",
    "        listeMust = []\n",
    "        listeSort = []\n",
    "        \n",
    "             \n",
    "        \n",
    "        if isRandom :\n",
    "                  \n",
    "            listeMust.append({ \"range\" : {\n",
    "                                    \"ID_random\" : {\n",
    "                                        \"gte\" :ID_random_min,\n",
    "                                        \"lt\" : ID_random_max,\n",
    "                                                    },\n",
    "                                    },\n",
    "                              })\n",
    "                    \n",
    "        if isID :\n",
    "            rangeID = { \"range\" : {\n",
    "                                    \"ID\" : {\n",
    "                                        \"gte\" :ID_min,\n",
    "                                        \"lte\" : ID_max,\n",
    "                                                    },\n",
    "                                    },\n",
    "                              }\n",
    "            \n",
    "            \n",
    "            listeMust.append (rangeID)\n",
    "            \n",
    "            \n",
    "        \n",
    "        if not ID_sort is None :\n",
    "            sort = {'ID' : {'order' : ID_sort},}\n",
    "            listeSort.append(sort)\n",
    "        \n",
    "        \n",
    "        \n",
    "        query = {'_source': _source,\n",
    "                      \"query\": {'bool': {'must': listeMust,\n",
    "                                        },},\n",
    "                                                    \n",
    "                       \"sort\" : listeSort,\n",
    "                    }\n",
    "                        \n",
    "                    \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print (index, \" et \",query, 'pour size =', size)\n",
    "        res = self.es.search (index = index, body = query , size = size)\n",
    "        hits = res['hits']\n",
    "        nombre= hits['total'] ['value']\n",
    "        vrai_hits= hits['hits']\n",
    "                   \n",
    "        return nombre, vrai_hits\n",
    "    \n",
    "    \n",
    "    \n",
    "    def search_par_bloc (self,\n",
    "                         index,\n",
    "                         \n",
    "                         ID,                     # inused Mais compatibilite oblige\n",
    "                         ID_reference_min,\n",
    "                         ID_reference_max ,\n",
    "                         ID_reference_sort = 'asc',\n",
    "                         isReference = True,\n",
    "                         \n",
    "                         isID = False,\n",
    "                         ID_min = \"\",\n",
    "                         ID_max  = \"\",\n",
    "                         ID_sort  = 'asc',\n",
    "                         \n",
    "                         isVariable = False,\n",
    "                         nom_variableQuery = None,\n",
    "                         variable_min = \"\",\n",
    "                         variable_max = \"\",\n",
    "                         variable_sort = 'asc',\n",
    "                         _source = None,\n",
    "                         \n",
    "                         size = 10000 ,\n",
    "                         \n",
    "                        ) :\n",
    "        \n",
    "        #modif ################################################\n",
    "        # warning toujours encadre par ID reference (à mettre au pas.....)\n",
    "        #         ascendant ou descendant est une propriete de chaque variable\n",
    "        listeMust = []\n",
    "        listeSort = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if isReference :\n",
    "            taille = len (self.ID_reference_base)\n",
    "            ID_reference_min_string  = (self.ID_reference_base + str(ID_reference_min) ) [-taille:]\n",
    "            ID_reference_max_string  = (self.ID_reference_base + str(ID_reference_max) ) [-taille:]\n",
    "            \n",
    "            listeMust.append({ \"range\" : {\n",
    "                                    \"ID_reference\" : {\n",
    "                                        \"gte\" :ID_reference_min_string,\n",
    "                                        \"lt\" : ID_reference_max_string,\n",
    "                                                    },\n",
    "                                    },\n",
    "                              })\n",
    "        \n",
    "        if not ID_reference_sort is None :\n",
    "            sort = {'ID_reference' : {'order' : ID_reference_sort},}\n",
    "            listeSort.append(sort)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        if isVariable :\n",
    "            \n",
    "            \n",
    "            rangeVariable = { \"range\" : {\n",
    "                                    nom_variableQuery : {\n",
    "                                                    \"gte\" :variable_min,\n",
    "                                                    \"lt\" : variable_max,\n",
    "                                                                },\n",
    "                                    },\n",
    "                              }\n",
    "            listeMust.append (rangeVariable)\n",
    "            \n",
    "        if not variable_sort is None :\n",
    "            \n",
    "            sort = {nom_variableQuery : {'order' : variable_sort},}\n",
    "            listeSort.append(sort)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "        if isID :\n",
    "                           \n",
    "            rangeID = { \"range\" : {\n",
    "                                    \"ID\" : {\n",
    "                                        \"gte\" :ID_min,\n",
    "                                        \"lte\" : ID_max,\n",
    "                                                    },\n",
    "                                    },\n",
    "                              }\n",
    "            \n",
    "            \n",
    "            listeMust.append (rangeID)\n",
    "            \n",
    "            \n",
    "        \n",
    "        if not ID_sort is None :\n",
    "            sort = {'ID' : {'order' : ID_sort},}\n",
    "            listeSort.append(sort)\n",
    "        \n",
    "        \n",
    "        if _source is None :\n",
    "            query = {\"query\": {'bool': {'must': listeMust,\n",
    "                                        },},\n",
    "                  \"sort\" : listeSort,\n",
    "                    }\n",
    "        else :\n",
    "            query = {'query' : query,\n",
    "                     '_source' : _source}\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('dans la classe, query =', query)\n",
    "        \n",
    "        res = self.es.search (index= index, body = query , size = size)\n",
    "        hits = res['hits']\n",
    "        nombre= hits['total'] ['value']\n",
    "        vrai_hits= hits['hits']\n",
    "        return nombre, vrai_hits \n",
    "    \n",
    "    def tri (self, hits) :\n",
    "        liste = []\n",
    "        i = 0\n",
    "        for data in hits :\n",
    "            x = data ['_source'] ['ID_reference']\n",
    "            liste.append([i, x])\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        liste_trie = sorted (liste, key = lambda d  : (d[1], d[0]) )\n",
    "\n",
    "        liste_hits_trie = []\n",
    "        for numero, _ in liste_trie :\n",
    "            data = hits [numero]\n",
    "            liste_hits_trie.append(data)\n",
    "            continue\n",
    "\n",
    "        return liste_hits_trie\n",
    "        \n",
    "    \n",
    "    \n",
    "    def close (self,) :\n",
    "        \n",
    "        self.es.indices.refresh()       \n",
    "        self.es.close()\n",
    "        \n",
    "        return\n",
    "    \n",
    "      \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%save test_kernel_vecteur.py 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecteur OK\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from datetime import datetime\n",
    "\n",
    "from Entree_sortie_lock import Entree_sortie_lock\n",
    "#from Kernel_BE import Kernel\n",
    "\n",
    "def iterator (nombre) :\n",
    "    vecteurG = [1.]*300\n",
    "    paragrapheG = ['essai']*1000\n",
    "    for i in range(0, nombre ):\n",
    "        doc = {'ID' : i ,\n",
    "               'vecteur' : vecteurG,\n",
    "               'ID_random' : randint (1, 1000000),\n",
    "               'paragraphe' : paragrapheG }\n",
    "        #print (doc ['ID'])\n",
    "        yield doc\n",
    "        \n",
    "def test_vecteur () :\n",
    "    \n",
    "    systeme = {  \n",
    "    \"createur\" : \"generic\", \n",
    "    \"date_emetteur\" : str(datetime.now()),\n",
    "    \"http_auth\" : None,\n",
    "    \"timeout\" : 10,\n",
    "    \"host\" : \"localhost\", \n",
    "    \"port\" : 9200 ,\n",
    "    \"zipChoisi\" : 'bz2',\n",
    "    \"index_log_error\" : \"trace1\",\n",
    "    \"index_log_warning\" : \"trace2\",\n",
    "    \"index_log_trace\" : \"trace3\",\n",
    "    \"index_system\" : \"systeme\",\n",
    "    \"isPurge_existing_index_log\" : True,\n",
    "    \"extra_elasticsearch_args\" : None,\n",
    "    \"trace\" : False,\n",
    "    \"ID_reference_base\" : \"000000000000000000000000000000\",\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "    k = Kernel (systeme)\n",
    "    nombre_vecteur = 11\n",
    "    docs = iterator (nombre_vecteur)\n",
    "    index = 'test'\n",
    "    isPurge_existing_index = True\n",
    "    resultat = k.bulk_vecteur (docs,\n",
    "                                   index = index,\n",
    "                                  isPurge_existing_index = isPurge_existing_index,\n",
    "                                  chunk_size = 2000,\n",
    "                                 )\n",
    "    \n",
    "    assert (resultat == True)\n",
    "\n",
    "    index = 'test'\n",
    "    \n",
    "    #print (\"premiere lecture\")\n",
    "    #print ('index =', index)\n",
    "    nombre, vrai_hits = k.search_par_bloc_vecteur(\n",
    "                                                     index,\n",
    "                                                     isRandom = False,\n",
    "\n",
    "                                                     isID = False,\n",
    "                                                     ID_min = \"0\",\n",
    "                                                     ID_max  = str(nombre_vecteur),\n",
    "                                                     ID_sort  = 'asc',\n",
    "                                                     size = 1000 ,\n",
    "                                                )\n",
    "    \n",
    "    \n",
    "    #print (\"recu premiere lecture = \\n\",len(vrai_hits) )\n",
    "    #print (\"recu premiere lecture = \\n\", vrai_hits [0])\n",
    "    assert ( nombre == nombre_vecteur ), 'erreur nombre de bulk'\n",
    "\n",
    "    #print ()\n",
    "    #print (\"seconde lecture\")\n",
    "    #print ('index =', index)\n",
    "    nombre, vrai_hits = k.search_par_bloc_vecteur(\n",
    "                                                     index,\n",
    "                                                     isRandom = False,\n",
    "                                                     isID = True,\n",
    "                                                     ID_min = 0,\n",
    "                                                     ID_max  = 9,\n",
    "                                                     ID_sort  = 'asc',\n",
    "                                                     size = 1000 ,\n",
    "\n",
    "                                                    )\n",
    "    \n",
    "    #print (\"recu seconde lecture = \\n\",len(vrai_hits) )\n",
    "    #print (\"recu seconde lecture = \\n\", vrai_hits [0])\n",
    "    assert nombre == 10  , ' erreur sur search vecteur :' + str(nombre)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    test_vecteur ()\n",
    "    print ('vecteur OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%save test_search_par_bloc.py 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin test search par bloc OK\n"
     ]
    }
   ],
   "source": [
    "import random, time, copy, json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "path = \"../outils\"\n",
    "if path not in sys.path : \n",
    "    sys.path.append (path)\n",
    "from Kernel_BE import Kernel\n",
    "\n",
    "from pprint import PrettyPrinter \n",
    "def P (stuff , pp = PrettyPrinter(indent=4)) :\n",
    "    return pp.pprint(stuff)\n",
    "\n",
    "\n",
    "def test_search_par_bloc() :\n",
    "    arg = {}\n",
    "\n",
    "    arg ['pathDico_evenements'] = '../data/dico_evenements_2.txt'\n",
    "    arg ['pathDico_systeme'] = '../data/dico_systeme_2.txt'\n",
    "    #  variable pour alimentation bloc\n",
    "\n",
    "    arg ['ID_reference_min'] = 0\n",
    "    arg ['ID_reference_max'] = 100000000\n",
    "    arg ['ID_reference_sort'] = 'asc'\n",
    "    arg ['isReference'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    arg ['isVariable'] =  True\n",
    "    arg ['nom_variableQuery'] = \"date_evenement\"\n",
    "    arg ['variable_min'] = '2021-02-01 00:00:00'\n",
    "    arg ['variable_max'] = '2021-02-04 00:00:00'\n",
    "    arg ['variable_sort'] = 'asc'\n",
    "\n",
    "    arg ['isID'] = True\n",
    "    arg ['ID_min'] = \"couple_cadre_1\"\n",
    "    arg ['ID_max']  = \"couple_cadre_sup_1\"\n",
    "    arg ['ID_sort']  = None\n",
    "    arg ['isTrace'] = True\n",
    "\n",
    "\n",
    "    systeme = {  \n",
    "              \"createur\" : \"generic\", \n",
    "              \"date_emetteur\" : str(datetime.now()),\n",
    "              \"http_auth\" : None,\n",
    "              \"timeout\" : 10,\n",
    "              \"host\" : \"localhost\", \n",
    "              \"port\" : 9200 ,\n",
    "              \"zipChoisi\" : 'bz2',\n",
    "              \"index_log_error\" : \"trace1\",\n",
    "              \"index_log_warning\" : \"trace2\",\n",
    "              \"index_log_trace\" : \"trace3\",\n",
    "              \"index_system\" : \"systeme\",\n",
    "              \"isPurge_existing_index_log\" : True,\n",
    "              \"extra_elasticsearch_args\" : None,\n",
    "              \"trace\" : False,\n",
    "              \"ID_reference_base\" : \"000000000000000000000000000000\",\n",
    "\n",
    "\n",
    "                    }\n",
    "\n",
    "\n",
    "    kernel = Kernel(systeme)\n",
    "\n",
    "    debut_bloc = arg['ID_reference_min']\n",
    "    fin_bloc = arg['ID_reference_max']\n",
    "    ID_reference_sort = arg ['ID_reference_sort']\n",
    "    isReference = arg ['isReference']\n",
    "\n",
    "\n",
    "\n",
    "    isID = arg['isID']\n",
    "    ID_min = arg ['ID_min']\n",
    "    ID_max  = arg ['ID_max']\n",
    "    ID_sort  = arg ['ID_sort']\n",
    "\n",
    "    isVariable =  arg ['isVariable']\n",
    "    nom_variableQuery = arg ['nom_variableQuery']\n",
    "    variable_min = arg ['variable_min']\n",
    "    variable_max = arg ['variable_max']\n",
    "    variable_sort = arg ['variable_sort']\n",
    "\n",
    "\n",
    "    isTrace = arg ['isTrace']\n",
    "    \n",
    "    \n",
    "    size = 700\n",
    "    taille_lu, hits = kernel.search_par_bloc (\"data_fake_\",\n",
    "                                               \" \", #deprecated\n",
    "                                               debut_bloc,\n",
    "                                               fin_bloc,\n",
    "                                               size = size,\n",
    "                                               isReference = isReference,\n",
    "                                               ID_reference_sort = ID_reference_sort,\n",
    "\n",
    "                                               isID = isID,\n",
    "                                               ID_min = ID_min,\n",
    "                                               ID_max  = ID_max ,\n",
    "                                               ID_sort  = ID_sort,\n",
    "\n",
    "                                               isVariable = isVariable,\n",
    "                                               nom_variableQuery = nom_variableQuery,\n",
    "                                               variable_min = variable_min,\n",
    "                                               variable_max = variable_max,\n",
    "                                               variable_sort = variable_sort,\n",
    "                                             )\n",
    "\n",
    "\n",
    "    assert taille_lu == 154, 'erreur sur search par bloc' \n",
    "    \n",
    "    arg = {}\n",
    "    nom_environnement = 'test'\n",
    "    arg ['nom_environnement'] =  'nom_environnement'\n",
    "    \n",
    "    \n",
    "    pathFile_evenements = '/dico_evenements_2.json'\n",
    "    pathFile_systeme = '/dico_systeme_2.json'\n",
    "\n",
    "    arg_entree_sortie_lock = {} \n",
    "    arg_entree_sortie_lock ['nom_environnement'] = nom_environnement\n",
    "    arg_entree_sortie_lock['pathFile'] = pathFile_evenements\n",
    "    Entree_sortie_evenements = Entree_sortie_lock (arg_entree_sortie_lock)\n",
    "    dico_evenements, etat = Entree_sortie_evenements.lire()\n",
    "    arg ['pathDico_evenements'] = dico_evenements\n",
    "    #P (dico_evenements)\n",
    "\n",
    "    arg_entree_sortie_lock ['pathFile'] = pathFile_systeme\n",
    "    Entree_sortie_systeme = Entree_sortie_lock (arg_entree_sortie_lock)\n",
    "    dico_systeme, etat = Entree_sortie_systeme.lire()\n",
    "    arg ['pathDico_systeme'] = dico_systeme\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  variable pour alimentation bloc\n",
    "\n",
    "    arg ['ID_reference_min'] = 0\n",
    "    arg ['ID_reference_max'] = 100000000\n",
    "    arg ['ID_reference_sort'] = None\n",
    "    arg ['isReference'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    arg ['isVariable'] = True\n",
    "    arg ['nom_variableQuery'] = \"date_evenement\"\n",
    "    arg ['variable_min'] = '2021-02-01 00:00:00'\n",
    "    arg ['variable_max'] = '2021-02-09 00:00:00'\n",
    "    arg ['variable_sort'] = None\n",
    "\n",
    "    arg ['isID'] = False\n",
    "    arg ['ID_min'] = \"couple_cadre_0\"\n",
    "    arg ['ID_max']  = \"homme_ouvrier_1\"\n",
    "    arg ['ID_sort']  = 'asc'\n",
    "    \n",
    "    arg ['isTrace'] = False\n",
    "    \n",
    "    debut_bloc = arg['ID_reference_min']\n",
    "    fin_bloc = arg['ID_reference_max']\n",
    "    ID_reference_sort = arg ['ID_reference_sort']\n",
    "    isReference = arg ['isReference']\n",
    "\n",
    "\n",
    "\n",
    "    isID = arg['isID']\n",
    "    ID_min = arg ['ID_min']\n",
    "    ID_max  = arg ['ID_max']\n",
    "    ID_sort  = arg ['ID_sort']\n",
    "\n",
    "    isVariable =  arg ['isVariable']\n",
    "    nom_variableQuery = arg ['nom_variableQuery']\n",
    "    variable_min = arg ['variable_min']\n",
    "    variable_max = arg ['variable_max']\n",
    "    variable_sort = arg ['variable_sort']\n",
    "    \n",
    "\n",
    "    isTrace = arg ['isTrace']\n",
    "    \n",
    "    \n",
    "    size = 1344\n",
    "    taille_lu, hits = kernel.search_par_bloc (\"data_fake\",\n",
    "                                               \" \", #deprecated\n",
    "                                               debut_bloc,\n",
    "                                               fin_bloc,\n",
    "                                               size = size,\n",
    "                                               isReference = isReference,\n",
    "                                               ID_reference_sort = ID_reference_sort,\n",
    "\n",
    "                                               isID = isID,\n",
    "                                               ID_min = ID_min,\n",
    "                                               ID_max  = ID_max ,\n",
    "                                               ID_sort  = ID_sort,\n",
    "\n",
    "                                               isVariable = isVariable,\n",
    "                                               nom_variableQuery = nom_variableQuery,\n",
    "                                               variable_min = variable_min,\n",
    "                                               variable_max = variable_max,\n",
    "                                               variable_sort = variable_sort,\n",
    "                                             )\n",
    "    \n",
    "    \n",
    "    \n",
    "    liste_ID = []\n",
    "    memoire = {}\n",
    "    for hit in hits :\n",
    "        enreg = hit ['_source']\n",
    "        ID = enreg ['ID']\n",
    "        \n",
    "        if not ID in memoire :\n",
    "            liste_ID.append (ID)\n",
    "            memoire [ID] = None\n",
    "        continue\n",
    "        \n",
    "    liste_ID_voulu = [ID for ID in memoire.keys()]\n",
    "    liste_ID_voulu.sort ()\n",
    "    \n",
    "    assert liste_ID_voulu == liste_ID\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    test_search_par_bloc()\n",
    "    print ('fin test search par bloc OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%save test_kernel_general.py 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin du test\n"
     ]
    }
   ],
   "source": [
    "import json, time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from Kernel_BE import Kernel\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def  test_kernel_general () :\n",
    "\n",
    "    systeme = {  \n",
    "              \"createur\" : \"generic\", \n",
    "              \"date_emetteur\" : str(datetime.now()),\n",
    "              \"http_auth\" : None,\n",
    "              \"timeout\" : 10,\n",
    "              \"host\" : \"localhost\", \n",
    "              \"port\" : 9200 ,\n",
    "              \"zipChoisi\" : 'bz2',\n",
    "              \"index_log_error\" : \"trace1\",\n",
    "              \"index_log_warning\" : \"trace2\",\n",
    "              \"index_log_trace\" : \"trace3\",\n",
    "              \"index_system\" : \"systeme\",\n",
    "              \"isPurge_existing_index_log\" : True,\n",
    "              \"extra_elasticsearch_args\" : None,\n",
    "              \"trace\" : False,\n",
    "              \"ID_reference_base\" : \"000000000000000000000000000000\",\n",
    "\n",
    "\n",
    "                    }\n",
    "\n",
    "    ID_reference_base = systeme [\"ID_reference_base\"]\n",
    "    k = Kernel(systeme)\n",
    "    index = \"test\"\n",
    "    k.create_index (index)\n",
    "    k.delete_index (index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    array = np.array ([i for i in range(0, 10)])\n",
    "    data = k.array2liste (array,)\n",
    "    arrayF = k.liste2array( data,dtype = np.int32)\n",
    "\n",
    "    assert array.any()  == arrayF.any() , 'array <=> faux'\n",
    "\n",
    "    array = np.array ([float(i)*0.1 for i in range(0, 10)])\n",
    "    data = k.array2liste (array,)\n",
    "    arrayF = k.liste2array( data,dtype = np.float64)\n",
    "\n",
    "    assert array.any()  == arrayF.any(), 'array <=> faux'\n",
    "    #print (array)\n",
    "    #print (arrayF)\n",
    "    ID_reference_base = systeme [\"ID_reference_base\"]\n",
    "    taille = len(ID_reference_base)\n",
    "    def iterateur (kernel, nombre = 1000) :\n",
    "\n",
    "        for i in range(0, nombre) :\n",
    "            for j in range(0,10) :\n",
    "                dico = {\n",
    "                      \"ID\" : (\"0000\"+ str(i)) [-4:] ,\n",
    "                      \"date_evenement\" : (ID_reference_base + str(i))[-taille:],\n",
    "\n",
    "                      \"ID_reference\" : (ID_reference_base  +str(i))[-taille:],\n",
    "\n",
    "                       \"nom_variable\" : \"variable_\"+ str(j),\n",
    "                       \"valeur\" : 1000000000000,\n",
    "                }\n",
    "                yield dico\n",
    "\n",
    "    nombre = 10000    \n",
    "    docs = iterateur (k, nombre = nombre)\n",
    "    index = \"test\"\n",
    "\n",
    "    t = time.time()\n",
    "    k.bulk ( docs, index, isPurge_existing_index = True,)\n",
    "    #print (\"bulk =\",k.count (index) == nombre*10, \" en temps =\", time.time () - t)\n",
    "\n",
    "\n",
    "\n",
    "    # on test les logs\n",
    "\n",
    "    #auteur, etape,  message\n",
    "\n",
    "    auteur = \"test1\"\n",
    "    etape = \"etape1\"\n",
    "    message = \"message1\"\n",
    "\n",
    "    k.log_error (auteur, etape,  message)\n",
    "    k.log_error (auteur, etape,  message)\n",
    "\n",
    "    k.log_warning (auteur, etape,  message)\n",
    "    k.log_warning (auteur, etape,  message)\n",
    "\n",
    "    k.log_trace (auteur, etape,  message)\n",
    "    k.log_trace (auteur, etape,  message)\n",
    "    \n",
    "    voulu = {'origine': 'error', 'auteur': 'test1', 'etape': 'etape1',\n",
    "             'message': 'message1'}\n",
    "    \n",
    "    result = k.get_logs_error() \n",
    "    assert len (result) == 2, \"log error\"\n",
    "    voulu ['origine'] = 'error'\n",
    "    r = result [0]\n",
    "    del r ['date']\n",
    "    assert voulu == r, str(result [0])\n",
    "    \n",
    "    result = k.get_logs_warning()\n",
    "    assert len (result) == 2, \"log warning\"\n",
    "    voulu ['origine'] = 'warning'\n",
    "    r = result [0]\n",
    "    del r ['date']\n",
    "    assert voulu == r, \"log warning\"\n",
    "    \n",
    "    result = k.get_logs_trace()\n",
    "    assert len (result) == 2, \"log trace\"\n",
    "    voulu ['origine'] = 'trace'\n",
    "    r = result [0]\n",
    "    del r ['date']\n",
    "    assert voulu == r, \"log trace\"\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # test search bloc ######################\n",
    "\n",
    "    j = 5\n",
    "\n",
    "    i = 0\n",
    "    pas = 1000 # donne 1000 ligne\n",
    "\n",
    "    ID_reference_min = i\n",
    "    ID_reference_max = i + pas\n",
    "    ID = str(i+2)\n",
    "    index = \"test\"\n",
    "    # test avec un size ################\n",
    "\n",
    "\n",
    "    time.time()\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "                             ID,                     # inused Mais compatibilite oblige\n",
    "                             ID_reference_min,\n",
    "                             ID_reference_max ,\n",
    "                             ID_reference_sort = None,\n",
    "\n",
    "                             isID = False,\n",
    "                             ID_min = \"\",\n",
    "                             ID_max  = \"\",\n",
    "                             ID_sort  = 'asc',\n",
    "\n",
    "                             isVariable = False,\n",
    "                             nom_variableQuery = None,\n",
    "                             variable_min = \"\",\n",
    "                             variable_max = \"\",\n",
    "                             variable_sort = None,\n",
    "\n",
    "                             size = pas*10 ,\n",
    "                                     )\n",
    "\n",
    "    assert taille != 0  , 'erreur de lecture'\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    assert taille == len(hits)  and taille == pas * 10 , 'erreur taille dans lecture de 10000 éléments'\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "                             ID,                     # inused Mais compatibilite oblige\n",
    "                             ID_reference_min,\n",
    "                             ID_reference_max ,\n",
    "                             ID_reference_sort = None,\n",
    "\n",
    "                             isID = False,\n",
    "                             ID_min = \"\",\n",
    "                             ID_max  = \"\",\n",
    "                             ID_sort  = None,\n",
    "\n",
    "                             isVariable = False,\n",
    "                             nom_variableQuery = None,\n",
    "                             variable_min = \"\",\n",
    "                             variable_max = \"\",\n",
    "                             variable_sort = None,\n",
    "\n",
    "                             size = pas*10 ,\n",
    "                                     )\n",
    "\n",
    "    \n",
    "    assert taille == len(hits)  and taille == 10000 , 'erreur taille dans lecture de 10000 éléments'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    r = hits [0]['_source'] ['ID_reference']\n",
    "\n",
    "    taille_1 = len(ID_reference_base)\n",
    "    voulu = (ID_reference_base  +str (ID_reference_min))[-taille_1:]\n",
    "\n",
    "    assert r == voulu , 'erreur dans le contenu du premier hit'\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    r = hits [taille - 1]['_source'] ['ID_reference']\n",
    "\n",
    "    taille_1 = len(ID_reference_base)             \n",
    "    voulu = (ID_reference_base  + str(ID_reference_max-1))[-taille_1:] # on calcul le ID_reference\n",
    "    assert r == voulu , 'erreur dans le contenu du dernier hit'\n",
    "    \n",
    "\n",
    "\n",
    "    # avec ID voulu\n",
    "    j = 5 # ID\n",
    "    ID_min = (\"0000\"+ str(j)) [-4:] # il apparait une fois par ligne donc il a 10 variables\n",
    "    ID_max = (\"0000\"+ str(j+1)) [-4:]\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    pas = 100 # nombre de ligne\n",
    "\n",
    "\n",
    "    ID_reference_min = i \n",
    "    ID_reference_max = i + pas\n",
    "    index = \"test\"\n",
    "    t = time.time()\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                      isReference = True,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min ,\n",
    "                                     ID_max  = ID_max ,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = False,\n",
    "                                     nom_variableQuery = None,\n",
    "                                     variable_min = \"\",\n",
    "                                     variable_max = \"\",\n",
    "                                     variable_sort = None,\n",
    "                                      size = pas*10 ,\n",
    "                                     )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    assert taille == len(hits) and taille == 20 , 'nombre d evenements pour 1 ID'\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ID_voulu =  (\"0000\"+ str(j)) [-4:]    # ID_min \n",
    "    taille_variable = 10\n",
    "    liste_variable =  []\n",
    "    for i in range(0, taille_variable ) :\n",
    "        nom_variable = hits [i] ['_source'] ['nom_variable']\n",
    "        assert hits [i] ['_source'] ['ID'] == ID_min\n",
    "        \n",
    "        liste_variable.append (nom_variable)\n",
    "        continue\n",
    "\n",
    "    voulu = ['variable_0', 'variable_1', 'variable_2', 'variable_3', 'variable_4', 'variable_5',\n",
    "             'variable_6', 'variable_7', 'variable_8', 'variable_9']\n",
    "\n",
    "    assert liste_variable == voulu , 'variable non trie par ID_reference'\n",
    "        \n",
    "\n",
    "\n",
    "    # on verifie que ID_reference est trie\n",
    "\n",
    "    ID_reference_courant = \"\"\n",
    "    for i in range(0, 10) :\n",
    "        ID_reference = hits[i] ['_source'] ['ID_reference']\n",
    "        assert ID_reference >= ID_reference_courant\n",
    "        \n",
    "        ID_reference_courant = ID_reference\n",
    "        continue\n",
    "\n",
    "    # avec ID voulu mais non ID dans ID_reference\n",
    "    j = 5 # ID\n",
    "    ID_min = (\"0000\"+ str(j)) [-4:] # il apparait une fois par ligne donc il a 10 variables\n",
    "    ID_max = (\"0000\"+ str(j+1)) [-4:]\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    pas = 5\n",
    "\n",
    "\n",
    "    ID_reference_min = i \n",
    "    ID_reference_max = i + pas\n",
    "    index = \"test\"\n",
    "    t = time.time()\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = True,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min ,\n",
    "                                     ID_max  = ID_max ,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = False,\n",
    "                                     nom_variableQuery = None,\n",
    "                                     variable_min = \"\",\n",
    "                                     variable_max = \"\",\n",
    "                                     variable_sort = None,\n",
    "\n",
    "                                     size = pas*10 ,)\n",
    "\n",
    "\n",
    "    assert  taille == 0 , 'on  load un ID sur une plage ou il n est pas'\n",
    "        \n",
    "\n",
    "    # on croise date et ID_ref\n",
    "\n",
    "    j = 5 # ID\n",
    "    ID_min = (\"0000\"+ str(j)) [-4:] # il apparait une fois par ligne donc il a 10 variables\n",
    "    ID_max = (\"0000\"+ str(j+1)) [-4:]\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    pas = 5\n",
    "\n",
    "\n",
    "    ID_reference_min = i \n",
    "    ID_reference_max = i + pas\n",
    "\n",
    "    variable_min = 0\n",
    "    variable_max = 2\n",
    "\n",
    "    taille = len(ID_reference_base)\n",
    "    variable_min_string = (ID_reference_base + str(variable_min))[-taille:]\n",
    "    variable_max_string = (ID_reference_base + str(variable_max))[-taille:]\n",
    "\n",
    "    index = \"test\"\n",
    "    t = time.time()\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = True,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min ,\n",
    "                                     ID_max  = ID_max ,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = variable_min_string,\n",
    "                                     variable_max = variable_max_string,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = pas*10 ,)\n",
    "\n",
    "\n",
    "    assert taille == 0 , 'reference 0, 5 et ID 5, 6 et date_evenement 0, 2 taille ?'\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    j = 5 # ID\n",
    "    ID_min = (\"0000\"+ str(j)) [-4:] # il apparait une fois par ligne donc il a 10 variables\n",
    "    ID_max = (\"0000\"+ str(j+1)) [-4:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    pas = 5\n",
    "\n",
    "    ID_reference_min = i \n",
    "    ID_reference_max = i + pas\n",
    "\n",
    "    variable_min = 0\n",
    "    variable_max = 2\n",
    "\n",
    "    taille = len(ID_reference_base)\n",
    "    variable_min_string = (ID_reference_base + str(variable_min))[-taille:]\n",
    "    variable_max_string = (ID_reference_base + str(variable_max))[-taille:]\n",
    "\n",
    "    index = \"test\"\n",
    "    t = time.time()\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'desc',\n",
    "                                     isReference = True,\n",
    "\n",
    "                                     isID = False,\n",
    "                                     ID_min = ID_min ,\n",
    "                                     ID_max  = ID_max ,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = variable_min_string,\n",
    "                                     variable_max = variable_max_string,\n",
    "                                     variable_sort = 'desc',\n",
    "\n",
    "                                     size = pas*10 ,)\n",
    "\n",
    "\n",
    "    assert taille == 20 , 'ID_reference et date_evenement ne correspondent pas taille'\n",
    "        \n",
    "    liste_date_evenement = []\n",
    "    liste_ID_reference = []\n",
    "\n",
    "    for hit in hits :\n",
    "        enreg = hit ['_source']\n",
    "        ID_reference = enreg ['ID_reference']\n",
    "        liste_ID_reference.append(ID_reference)\n",
    "\n",
    "        date_evenement = enreg ['date_evenement']\n",
    "        liste_date_evenement.append(date_evenement) \n",
    "\n",
    "        continue\n",
    "    isFirst = True    \n",
    "    for date, ID_reference in zip (liste_date_evenement, liste_ID_reference ) :\n",
    "        if isFirst :\n",
    "            date_courant, ID_reference_courant = date, ID_reference\n",
    "            isFirst = False\n",
    "        assert date  <= date_courant and ID_reference <= ID_reference_courant\n",
    "        \n",
    "        continue\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # test de search par date\n",
    "\n",
    "    index = \"test\"\n",
    "    t = time.time()\n",
    "\n",
    "    variable_min = 1\n",
    "    variable_max = 21\n",
    "\n",
    "    taille = len(ID_reference_base)\n",
    "    variable_min_string = (ID_reference_base + str(variable_min))[-taille:]\n",
    "    variable_max_string = (ID_reference_base + str(variable_max))[-taille:]\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = False,\n",
    "                                     ID_min = \"\",\n",
    "                                     ID_max  = \"\",\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = variable_min_string,\n",
    "                                     variable_max = variable_max_string,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = pas*10 ,)\n",
    "\n",
    "\n",
    "    assert taille == 200 , 'erreur dans search sur variable date_evenement'\n",
    "    \n",
    "\n",
    "    isFirst = True    \n",
    "    for hit in hits :\n",
    "        enreg = hit ['_source']\n",
    "        date = enreg ['date_evenement']\n",
    "        if isFirst :\n",
    "            assert date == '000000000000000000000000000001'\n",
    "            \n",
    "            date_courante = date\n",
    "            isFirst = False\n",
    "            continue\n",
    "        assert date >= date_courante , 'erreur de sens non asc'\n",
    "        \n",
    "        date_courante = date\n",
    "        continue\n",
    "\n",
    "\n",
    "    # test search par bloc temps X ID\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 0\n",
    "    ID_min = (\"0000\"+ str(i)) [-4:] \n",
    "    date_evenement_min = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "    ID_reference_min = (ID_reference_base  +str(i))[-taille:],\n",
    "\n",
    "    #max\n",
    "    i = 10\n",
    "    ID_max = (\"0000\"+ str(i)) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "    ID_reference_max = (ID_reference_base  +str(i))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = pas*10 ,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    assert taille == 100 , 'erreur de taille dans la lecture par bloc date X ID'\n",
    "    \n",
    "    ID_reference_base = systeme [\"ID_reference_base\"]\n",
    "    taille = len(ID_reference_base)\n",
    "    isFirst = True\n",
    "    numero_ligne = 0\n",
    "    for hit in hits :\n",
    "        doc = hit ['_source']\n",
    "        i = int(numero_ligne/10)\n",
    "        j = numero_ligne % 10\n",
    "        dico = {\n",
    "                      \"ID\" : (\"0000\"+ str(i)) [-4:] ,\n",
    "                      \"date_evenement\" : (ID_reference_base + str(i))[-taille:],\n",
    "\n",
    "                      \"ID_reference\" : (ID_reference_base  +str(i))[-taille:],\n",
    "\n",
    "                       \"nom_variable\" : \"variable_\"+ str(j),\n",
    "                       \"valeur\" : 1000000000000,\n",
    "                }\n",
    "        assert dico == doc , 'erreur de contenu dans le search bloc date x ID'\n",
    "            \n",
    "        numero_ligne += 1\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # test search par bloc ID_reference X ID\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 0\n",
    "    ID_min = (\"0000\"+ str(i)) [-4:] \n",
    "    date_evenement_min = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "    ID_reference_min = (ID_reference_base  +str(i))[-taille:],\n",
    "\n",
    "    #max\n",
    "    i = 10\n",
    "    ID_max = (\"0000\"+ str(i)) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "    ID_reference_max = (ID_reference_base  +str(i))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = True,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = False,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = pas*10 ,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    assert taille == 100 , 'erreur de taille dans la lecture par bloc date X ID'\n",
    "        \n",
    "\n",
    "    ID_reference_base = systeme [\"ID_reference_base\"]\n",
    "    taille = len(ID_reference_base)\n",
    "    isFirst = True\n",
    "    numero_ligne = 0\n",
    "    for hit in hits :\n",
    "        doc = hit ['_source']\n",
    "        i = int(numero_ligne/10)\n",
    "        j = numero_ligne % 10\n",
    "        dico = {\n",
    "                      \"ID\" : (\"0000\"+ str(i)) [-4:] ,\n",
    "                      \"date_evenement\" : (ID_reference_base + str(i))[-taille:],\n",
    "\n",
    "                      \"ID_reference\" : (ID_reference_base  +str(i))[-taille:],\n",
    "\n",
    "                       \"nom_variable\" : \"variable_\"+ str(j),\n",
    "                       \"valeur\" : 1000000000000,\n",
    "                }\n",
    "        assert  dico == doc , 'erreur de contenu dans le search bloc date x ID'\n",
    "            \n",
    "        numero_ligne += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "    # test search par bloc temps X en limitant ID\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 0\n",
    "    i_ID = 2\n",
    "    ID_min = (\"0000\"+ str(i_ID)) [-4:] \n",
    "    date_evenement_min = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "    ID_reference_min = (ID_reference_base  +str(i))[-taille:],\n",
    "\n",
    "    #max\n",
    "    i = 10\n",
    "    ID_max = (\"0000\"+ str(i_ID + 1 )) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "    ID_reference_max = (ID_reference_base  +str(i))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = pas*10 ,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    assert taille == 20 , 'erreur de taille dans la lecture par bloc date X ID avec  limitation de ID'\n",
    "        \n",
    "\n",
    "    ID_reference_base = systeme [\"ID_reference_base\"]\n",
    "    taille = len(ID_reference_base)\n",
    "    isFirst = True\n",
    "    numero_ligne = 0\n",
    "    ID_cherche = (\"0000\"+ str(i_ID)) [-4:]\n",
    "    ID_cherche_suivant  = (\"0000\"+ str(i_ID+1)) [-4:]\n",
    "    for hit in hits :\n",
    "        doc = hit ['_source']\n",
    "        if doc ['ID']  != ID_cherche and doc ['ID']  != ID_cherche_suivant:\n",
    "            print ('erreur de contenu dans le search bloc date x ID avec  limitation de ID')\n",
    "            print (\" voulu =\", ID_cherche)\n",
    "            print()\n",
    "            print (' lu =', doc ['ID'])\n",
    "            raise ValueError\n",
    "        numero_ligne += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # on test le count\n",
    "\n",
    "    taille = k.count(index)\n",
    "\n",
    "    assert taille == 100000 , 'erreur du count sur index lu='\n",
    "        \n",
    "\n",
    "\n",
    "    #  on essaye le count by search\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    ID_min = (\"0000\"+ str(i_ID)) [-4:] \n",
    "    date_evenement_min = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "    #max\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    inc = 20\n",
    "    ID_max = (\"0000\"+ str(i_ID + inc )) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i+inc))[-taille:]\n",
    "\n",
    "    ID_reference_min = 0\n",
    "\n",
    "    ID_reference_max = 1000\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = True,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = 100 ,\n",
    "\n",
    "                                     )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    ID_min = (\"0000\"+ str(i_ID)) [-4:] \n",
    "    date_evenement_min = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "    #max\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    inc = 20\n",
    "    ID_max = (\"0000\"+ str(i_ID + inc )) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i+inc))[-taille:]\n",
    "\n",
    "\n",
    "    ID_reference_min = 12\n",
    "    \n",
    "    ID_reference_max = 1000\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = True,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = 100 ,\n",
    "\n",
    "                                     )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    ID_min = (\"0000\"+ str(i_ID)) [-4:] \n",
    "    date_evenement_min = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "    #max\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    inc = 20\n",
    "    ID_max = (\"0000\"+ str(i_ID + inc )) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i+inc))[-taille:]\n",
    "\n",
    "\n",
    "    ID_reference_min = 0\n",
    "    #print ('ID_reference_min =', ID_reference_min)\n",
    "    ID_reference_max = 1000\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = True,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort = None,\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = None,\n",
    "\n",
    "                                     size =100 ,\n",
    "\n",
    "                                     )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #### ##########\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    ID_min = (\"0000\"+ str(i_ID)) [-4:] \n",
    "    date_evenement_min = (ID_reference_base + str(i))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "    #max\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    inc = 20\n",
    "    ID_max = (\"0000\"+ str(i_ID + inc )) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i+inc))[-taille:]\n",
    "\n",
    "    ID_reference_min = 0\n",
    "\n",
    "    ID_reference_max = 1000\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort = None,\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = None,\n",
    "\n",
    "                                     size =100 ,\n",
    "\n",
    "                                     )\n",
    "    \n",
    "    arg = {}\n",
    "    arg ['isTrace'] = False\n",
    "    \n",
    "    \n",
    "    #  variable pour alimentation bloc_date\n",
    "\n",
    "    arg ['ID_reference_min'] = 0\n",
    "    arg ['ID_reference_max'] = 100000000\n",
    "    arg ['ID_reference_sort'] = 'asc'\n",
    "    arg ['isReference'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    arg ['isVariable'] =  True\n",
    "    arg ['nom_variableQuery'] = \"date_evenement\"\n",
    "    arg ['variable_min'] = '2021-02-01 00:00:00.000'\n",
    "    arg ['variable_max'] = '2021-02-10 00:00:00.000'\n",
    "    arg ['variable_sort'] = 'asc'\n",
    "\n",
    "    arg ['isID'] = False\n",
    "    arg ['ID_min'] = \"couple_cadre_1\"\n",
    "    arg ['ID_max']  = \"couple_cadre_sup_1\"\n",
    "    arg ['ID_sort']  = 'asc'\n",
    "    \n",
    "    arg ['isTrace'] = False\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    arg = {}\n",
    "    arg ['isTrace'] = False\n",
    "    \n",
    "    \n",
    "    #  variable pour alimentation bloc_date\n",
    "\n",
    "    arg ['ID_reference_min'] = 0\n",
    "    arg ['ID_reference_max'] = 100000000\n",
    "    arg ['ID_reference_sort'] = 'asc'\n",
    "    arg ['isReference'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    arg ['isVariable'] =  True\n",
    "    arg ['nom_variableQuery'] = \"date_evenement\"\n",
    "    arg ['variable_min'] = '2021-02-01 00:00:00.000'\n",
    "    arg ['variable_max'] = '2021-02-10 00:00:00.000'\n",
    "    arg ['variable_sort'] = 'asc'\n",
    "\n",
    "    arg ['isID'] = False\n",
    "    arg ['ID_min'] = \"couple_cadre_1\"\n",
    "    arg ['ID_max']  = \"couple_cadre_sup_1\"\n",
    "    arg ['ID_sort']  = 'asc'\n",
    "    \n",
    "    arg ['isTrace'] = False\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # on avance en prenant la derniere date \n",
    "\n",
    "\n",
    "    hit = hits [len(hits) - 1]\n",
    "    enreg = hit ['_source']\n",
    "    date_evenement_min = enreg ['date_evenement']\n",
    "\n",
    "\n",
    "    taille = len(ID_reference_base)\n",
    "    # min\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    ID_min = (\"0000\"+ str(i_ID)) [-4:] \n",
    "    hit = hits [len(hits) - 1]\n",
    "    enreg = hit ['_source']\n",
    "    date_evenement_min_int = int(enreg ['date_evenement'])\n",
    "    date_evenement_min = (ID_reference_base + str(date_evenement_min_int + 1))[-taille:]\n",
    "\n",
    "\n",
    "\n",
    "    #max\n",
    "    i = 1\n",
    "    i_ID = 2\n",
    "    inc = 20\n",
    "    ID_max = (\"0000\"+ str(i_ID + inc )) [-4:] \n",
    "    date_evenement_max = (ID_reference_base + str(i+inc))[-taille:]\n",
    "\n",
    "    ID_reference_min = 0\n",
    "\n",
    "    ID_reference_max = 1000000\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = 100 ,\n",
    "\n",
    "                                     )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    hit = hits [len(hits) - 1]\n",
    "    enreg = hit ['_source']\n",
    "    date_evenement_min = enreg ['date_evenement']\n",
    "\n",
    "    \n",
    "\n",
    "    ######## data_fake\n",
    "\n",
    "    index = 'data_fake_'\n",
    "\n",
    "    # min\n",
    "\n",
    "    ID_min = \"couple_cadre_1\"\n",
    "    date_evenement_min = '2021-02-01 00:00:00'\n",
    "\n",
    "    #     \"couple_cadre_sup_0\", \"couple_cadre_sup_1\"               \n",
    "    #max\n",
    "\n",
    "    ID_max = \"couple_cadre_sup_1\"\n",
    "    date_evenement_max = '2021-02-20 00:00:00'\n",
    "\n",
    "    ID_reference_min = 0\n",
    "    ID_reference_max = 1000000\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = True,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = 'asc',\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort = 'asc',\n",
    "\n",
    "                                     size = 100 ,\n",
    "\n",
    "                                     )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    hit = hits [len(hits) - 1]\n",
    "    enreg = hit ['_source']\n",
    "\n",
    "    date_evenement_min = enreg ['date_evenement']\n",
    "    #v = convertir ( date_evenement_min )\n",
    "    r = date_evenement_min.split ('.')\n",
    "    date_evenement_min = r[0]\n",
    "    dateCourante = datetime.strptime(date_evenement_min, \"%Y-%m-%d %M:%S:%f\")\n",
    "    timestamp = datetime.timestamp(dateCourante)\n",
    "    timestamp +=1\n",
    "    date_evenement_min = datetime.fromtimestamp(timestamp)\n",
    "\n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     ID,                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = 'asc',\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = False,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = None,\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = date_evenement_min,\n",
    "                                     variable_max = date_evenement_max,\n",
    "                                     variable_sort  = None,\n",
    "\n",
    "                                     size = 100 ,\n",
    "\n",
    "                                     )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    hit = hits [0]\n",
    "    enreg = hit ['_source']\n",
    "    date_evenementcourant = enreg ['date_evenement']\n",
    "\n",
    "    for hit in hits :\n",
    "        enreg = hit ['_source']\n",
    "        date_evenement = enreg ['date_evenement']\n",
    "        ID = enreg ['ID']\n",
    "        variable = enreg ['nom_variable'] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    isFirst = True\n",
    "    for hit in hits :\n",
    "        if isFirst :\n",
    "            enreg = hit ['_source']\n",
    "            ID_reference = enreg ['ID_reference']\n",
    "            courant = ID_reference\n",
    "            continue\n",
    "\n",
    "        enreg = hit ['_source']\n",
    "        ID_reference = enreg ['ID_reference']\n",
    "        \n",
    "        assert courant <= ID_reference , 'erreur de tri sur ID_reference' \n",
    "            \n",
    "        courant= enreg ['ID_reference']\n",
    "        continue\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    test_kernel_general ()\n",
    "    print ('Fin du test')\n",
    "\n",
    "\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%save test_alimentation_bloc_date.py 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin test_alimentation_bloc_date\n"
     ]
    }
   ],
   "source": [
    "#### import json, time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from Kernel_BE import Kernel\n",
    "\n",
    "\n",
    "def test_alimentation_bloc_date ():\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  variable pour alimentation bloc_date\n",
    "    \n",
    "    systeme = {  \n",
    "    \"createur\" : \"generic\", \n",
    "    \"date_emetteur\" : str(datetime.now()),\n",
    "    \"http_auth\" : None,\n",
    "    \"timeout\" : 10,\n",
    "    \"host\" : \"localhost\", \n",
    "    \"port\" : 9200 ,\n",
    "    \"zipChoisi\" : 'bz2',\n",
    "    \"index_log_error\" : \"trace1\",\n",
    "    \"index_log_warning\" : \"trace2\",\n",
    "    \"index_log_trace\" : \"trace3\",\n",
    "    \"index_system\" : \"systeme\",\n",
    "    \"isPurge_existing_index_log\" : True,\n",
    "    \"extra_elasticsearch_args\" : None,\n",
    "    \"trace\" : False,\n",
    "    \"ID_reference_base\" : \"000000000000000000000000000000\",\n",
    "\n",
    "\n",
    "        }\n",
    "    \n",
    "\n",
    "    k = Kernel (systeme)\n",
    "    \n",
    "    index = 'data_fake'\n",
    "\n",
    "    ID_reference_min = 0\n",
    "    ID_reference_max = 100000000\n",
    "    ID_reference_sort = 'asc'\n",
    "    isReference = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    isVariable =  True\n",
    "    nom_variableQuery = \"date_evenement\"\n",
    "    variable_min = '2021-02-01 00:00:00.000'\n",
    "    variable_max = '2021-03-10 00:00:00.000'\n",
    "    variable_sort = 'asc'\n",
    "\n",
    "    isID = False\n",
    "    ID_min = \"couple_cadre_1\"\n",
    "    ID_max = \"couple_cadre_sup_1\"\n",
    "    ID_sort = 'asc'\n",
    "    \n",
    "    isTrace = False\n",
    "    size = 192*7\n",
    "    \n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     'ID',                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = None,\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = False,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = None,\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = variable_min,\n",
    "                                     variable_max = variable_max,\n",
    "                                     variable_sort  = 'asc',\n",
    "\n",
    "                                     size = size ,\n",
    "\n",
    "                                     )\n",
    "    \n",
    "    assert taille == size, \"erreur lecture globale sur date\"\n",
    "    \n",
    "    #print (\"dans lecture avec size =\", size, \" on a len(hist) =\",len(hits), \" et taille =\", taille)\n",
    "    taille_totale_lu = len(hits)\n",
    "    memoire = {}\n",
    "    date_max = \"\"\n",
    "    isFirst = True\n",
    "    for hit in hits :\n",
    "        enreg = hit ['_source']\n",
    "        date_evenement = enreg ['date_evenement']\n",
    "        if date_evenement > date_max :\n",
    "            date_max = date_evenement\n",
    "        \n",
    "        if isFirst :\n",
    "            taille_evenement = len(date_evenement)\n",
    "            isFirst = False\n",
    "        \n",
    "        if taille_evenement != len(date_evenement) :\n",
    "            print('### erreur possible pour date_evenement =',date_evenement) \n",
    "            raise ValueError\n",
    "        try :\n",
    "            memoire [date_evenement] += 1\n",
    "        except :\n",
    "            memoire [date_evenement] = 1\n",
    "        continue\n",
    "    \n",
    "    \n",
    "        \n",
    "    #print ('apres analyse de la premiere lecture, on a taille_evenement =',taille_evenement)\n",
    "    #print ('apres analyse de la premiere lecture, on a len (memoire) =',len(memoire))\n",
    "    #print ('apres analyse de la premiere lecture, on a date_max =',date_max)\n",
    "    #print ()\n",
    "                \n",
    "    \n",
    "    size = 700\n",
    "    \n",
    "    \n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     'ID',                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = None,\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = False,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = None,\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = variable_min,\n",
    "                                     variable_max = variable_max,\n",
    "                                     variable_sort  = 'asc',\n",
    "\n",
    "                                     size = size ,\n",
    "\n",
    "                                     )\n",
    "    \n",
    "    #print (\"dans lecture avec size =\", size, \" on a len(hist) =\",len(hits), \" et taille =\", taille)\n",
    "    #print ()\n",
    "    taille_deja_lu = len(hits)\n",
    "    \n",
    "    memoire = {}\n",
    "    date_max = \"\"\n",
    "    for hit in hits :\n",
    "        enreg = hit ['_source']\n",
    "        date_evenement = enreg ['date_evenement']\n",
    "        if date_evenement > date_max :\n",
    "            date_max = date_evenement\n",
    "            \n",
    "        try :\n",
    "            memoire [date_evenement] += 1\n",
    "        except :\n",
    "            memoire [date_evenement] = 1\n",
    "        continue\n",
    "    \n",
    "    #print ('apres analyse de la deuxieme lecture, on a len (memoire) =',len(memoire))\n",
    "    #print ('apres analyse de la deuxieme lecture, on a date_max (la plus grande) =',date_max)\n",
    "    #print ()\n",
    "    hit = hits [len(hits)- 1]\n",
    "    enreg = hit ['_source']\n",
    "    date_evenement_min = enreg ['date_evenement']\n",
    "    \n",
    "    \n",
    "    format_standard = '%Y-%m-%d %H:%M:%S.%f'\n",
    "    dateCourante = datetime.strptime(date_evenement_min, format_standard)\n",
    "    timestamp = datetime.timestamp(dateCourante)\n",
    "    timestamp += 1\n",
    "    date_evenement_min = str(datetime.fromtimestamp(timestamp))\n",
    "    \n",
    "    \n",
    "    #print ('preparation deuxieme lecture')\n",
    "    #print ('variable min calculée dans alimentation_bloc =',date_evenement_min)\n",
    "    #print ( 'et variable_max =' , variable_max)\n",
    "    \n",
    "    variable_min = date_evenement_min\n",
    "    \n",
    "    taille, hits = k.search_par_bloc (index,\n",
    "\n",
    "                                     'ID',                     # inused Mais compatibilite oblige\n",
    "                                     ID_reference_min,\n",
    "                                     ID_reference_max ,\n",
    "                                     ID_reference_sort = None,\n",
    "                                     isReference = False,\n",
    "\n",
    "                                     isID = False,\n",
    "                                     ID_min = ID_min,\n",
    "                                     ID_max  = ID_max,\n",
    "                                     ID_sort  = None,\n",
    "\n",
    "                                     isVariable = True,\n",
    "                                     nom_variableQuery = \"date_evenement\",\n",
    "                                     variable_min = variable_min,\n",
    "                                     variable_max = variable_max,\n",
    "                                     variable_sort  = 'asc',\n",
    "\n",
    "                                     size = size ,\n",
    "\n",
    "                                     )\n",
    "    #print (\"dans lecture bloc final  avec size =\", size, \" on a len(hist) =\",len(hits), \" et taille =\", taille)\n",
    "    #print ('bloc final len(hits) =', len(hits))\n",
    "    hit = hits [len(hits)- 1]\n",
    "    enreg = hit ['_source']\n",
    "    date_evenement_min = enreg ['date_evenement']\n",
    "    #print ('date_evenement finale apres la dernier lecture =', date_evenement_min)\n",
    "    \n",
    "    assert len(hits) + taille_deja_lu == taille_totale_lu, 'erreur de, lecture sur date'\n",
    "    \n",
    "if __name__ == '__main__' :\n",
    "    test_alimentation_bloc_date ()\n",
    "    print ('fin test_alimentation_bloc_date')    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "               \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
