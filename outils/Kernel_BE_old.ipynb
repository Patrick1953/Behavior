{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rolled-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%save Kernel_BE.py 21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "compatible-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8 y\n",
    "import bz2 \n",
    "import lzma\n",
    "import gzip \n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "from elasticsearch import Elasticsearch \n",
    "from elasticsearch.connection import Urllib3HttpConnection\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "class rien () :\n",
    "    def compress (self, x) :\n",
    "        return x\n",
    "    def decompress (self, x) :\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "class Kernel () :\n",
    "    def __init__ ( self, dico) :\n",
    "        '''\n",
    "        \n",
    "                  createur = \"generic\", \n",
    "                  date_emetteur = datetime.now(),\n",
    "                  http_auth = None,\n",
    "                  timeout=10,\n",
    "                  host = \"localhost\", \n",
    "                  port = 9200 ,\n",
    "                  zipChoisi = 'bz2',\n",
    "                  index_log_error = \"trace1\",\n",
    "                  index_log_warning = \"trace2\",\n",
    "                  index_log_trace = \"trace3\",\n",
    "                  index_system = \"systeme\",\n",
    "                  isPurge_existing_index_log = True,\n",
    "                  extra_elasticsearch_args = None,\n",
    "                  trace = False,\n",
    "                  \n",
    "        \n",
    "        ######### centralise les I/O #########\n",
    "        en entree \n",
    "        le createur du process (esemble de taches) \n",
    "        la date de lancement par defaut ce jour\n",
    "        \n",
    "        ensuite\n",
    "        pour elastic : host, port\n",
    "        pour le zip : le choix par nom if none on ne fait rien,\n",
    "        \n",
    "        ensuite pour debug la trace (log elastic)\n",
    "        '''\n",
    "        createur = dico [\"createur\"]\n",
    "        date_emetteur = dico [\"date_emetteur\"]\n",
    "        http_auth = dico [\"http_auth\"]\n",
    "        timeout = dico [\"timeout\"]\n",
    "        host = dico [\"host\"]\n",
    "        port = dico [\"port\"]\n",
    "        zipChoisi = dico [\"zipChoisi\"]\n",
    "        index_log_error = dico [\"index_log_error\"]\n",
    "        index_log_warning = dico [\"index_log_warning\"]\n",
    "        index_log_trace = dico [\"index_log_trace\"]\n",
    "        index_system = dico [\"index_system\"]\n",
    "        isPurge_existing_index_log = dico [\"isPurge_existing_index_log\"]\n",
    "        extra_elasticsearch_args = dico [\"extra_elasticsearch_args\"]\n",
    "        trace = dico [\"trace\"]\n",
    "        #modif ##########################################\"\n",
    "        self.ID_reference_base = dico [\"_ID_reference_base\"]\n",
    "        \n",
    "        self.createur = createur\n",
    "        self.date_emetteur = date_emetteur\n",
    "        self.trace = trace\n",
    "        \n",
    "        self.index_log_error = index_log_error\n",
    "        self.index_log_warning = index_log_warning\n",
    "        self.index_log_trace = index_log_trace\n",
    "        self.isPurge_existing_index_log = isPurge_existing_index_log\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.http_auth = http_auth\n",
    "        self.timeout = timeout\n",
    "        \n",
    "        if extra_elasticsearch_args is None:\n",
    "            extra_elasticsearch_args = {}\n",
    "        self.extra_elasticsearch_args = extra_elasticsearch_args\n",
    "\n",
    "        \n",
    "        self.es = Elasticsearch(\n",
    "                        connection_class=Urllib3HttpConnection, # fonction externe\n",
    "                        host=self.host,\n",
    "                        port=self.port,\n",
    "                        http_auth=self.http_auth, # donne pour authentification\n",
    "                        timeout=self.timeout,\n",
    "                        **self.extra_elasticsearch_args,\n",
    "                        )\n",
    "        \n",
    "        \n",
    "        # init du system\n",
    "        self.index_system = index_system\n",
    "        index = index_system\n",
    "        if isPurge_existing_index_log or not self.es.indices.exists(index=index):\n",
    "            self.delete_index (index)\n",
    "            self.create_index (index)\n",
    "            # init date pour recuperer les logsdate = datetime.datetime.now() mis dans creationDoc\n",
    "            doc = self.creationDoc (\"systeme\", \"kernel\", \"init\",  \"pour recuperer les logs\",)\n",
    "            self.index_doc (doc, index, _id = 1 )\n",
    "        \n",
    "        # intialisation compression de données voir pb \"byte to string et inversement\"        \n",
    "        self.dicoZip = {'bz2' : bz2,\n",
    "                  'lzma' : lzma,\n",
    "                   'gzip' : gzip,\n",
    "                        }\n",
    "        self.initZip (zipChoisi = zipChoisi)\n",
    "        \n",
    "        \n",
    "        \n",
    "               \n",
    "        # pour la lemmatization       \n",
    "        \n",
    "        self.liste_type = ['NOM', 'AUX', 'VER', 'ADV', 'PRE', 'ADJ', 'ONO', 'CON',\n",
    "                  'ART:def', 'ADJ:ind', 'PRO:ind', 'PRO:int', 'PRO:rel',\n",
    "                  'ADJ:num', 'PRO:dem', 'ADJ:dem', 'PRO:per', 'ART:ind',\n",
    "                  'LIA', 'PRO:pos', 'ADJ:pos', '', 'ADJ:int']\n",
    "        \n",
    "        self.index_regroupement = \"regroupement\"\n",
    "        \n",
    "        self.settings_regroupement = { \"settings\" : {\n",
    "                                      'index.mapping.total_fields.limit':100000,\n",
    "                                     }\n",
    "        }\n",
    "        \n",
    "        self.dico_settings = {'regroupement' : self.settings_regroupement ,\n",
    "                             }\n",
    "                              \n",
    "                              \n",
    "        \n",
    "        self.structure_du_lexique = [\"1_ortho\" , \n",
    "                                     \"3_lemme\" , \n",
    "                                     \"4_cgram\" , \n",
    "                                     \"5_genre\" , \n",
    "                                     \"6_nombre\" , \n",
    "                                     \"7_freqlemfilms2\" , \n",
    "                                     \"8_freqlemlivres\" , \n",
    "                                     \"9_freqfilms2\" , \n",
    "                                     \"10_freqlivres\" , \n",
    "                                     \"11_infover\" , \n",
    "                                     \"12_nbhomogr\" , \n",
    "                                     \"13_nbhomoph\" , \n",
    "                                     \"14_islem\" , \n",
    "                                     \"15_nblettres\" , \n",
    "                                     \"19_voisorth\" , \n",
    "                                     \"21_puorth\" , \n",
    "                                     \"22_puphon\" , \n",
    "                                     \"29_cgramortho\" , \n",
    "                                     \"30_deflem\" , \n",
    "                                     \"31_defobs\" , \n",
    "                                     \"32_old20\" , \n",
    "                                     \"33_pld20\" , \n",
    "                                     \"35_nbmorph\" , \n",
    "                                    ]\n",
    "        \n",
    "\n",
    "        \n",
    "        self.debut_fichier_regroupement = \"../../../data/Lexique383_group\" # a voir\n",
    "        \n",
    "    @property\n",
    "    def raise_on_error(self):\n",
    "        \"\"\"\n",
    "        Renvoyer False pout permettre à l'appelant de gérer le log d'erreur\n",
    "        dans le cas du bulk\n",
    "        \"\"\"\n",
    "        return False\n",
    "    \n",
    "    @property\n",
    "    def mapping_log(self,) :\n",
    "        \"\"\"\n",
    "        Dictionary with custom mapping or `None`.\n",
    "        probleme avec Elastic sur le mapping ??????????\n",
    "        \"\"\"\n",
    "        return None\n",
    "        \n",
    "    @property\n",
    "    def mapping(self):\n",
    "        \"\"\"\n",
    "        Dictionary with custom mapping or `None`.\n",
    "        probleme avec Elastic sur le mapping ??????????\n",
    "        \"\"\"\n",
    "        mapping =  {\n",
    "                        \"properties\": {\n",
    "                            \"ID\": {\n",
    "                                \"type\": \"keyword\" # formerly \"string\"\n",
    "                            },\n",
    "                            \"ID_reference\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            },\n",
    "                            \"date_evenement\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            },\n",
    "                            \"nom_variable\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            },\n",
    "                            \"valeur\" : {\n",
    "                                \"type\" : \"keyword\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                \n",
    "        \n",
    "        return mapping\n",
    "    \n",
    "    def liste2array(self, data,dtype = np.int32) :\n",
    "        return np.array(data, dtype = dtype)\n",
    "    \n",
    "    def array2liste (self,array,):\n",
    "        return array.tolist()\n",
    "        \n",
    "    def initRead (self, path) :\n",
    "        self.f = open(path,\"r\")\n",
    "        return\n",
    "    \n",
    "    def readIterator (self,sep = '|') :\n",
    "        while (True) :\n",
    "            li = self.f.readline ()\n",
    "            if li == \" \" :\n",
    "                raise ValueError\n",
    "            liste = li[:-1].split (sep)\n",
    "            yield  liste\n",
    "       \n",
    "    def compression (self, data) :\n",
    "        return self.zip.compress (data)\n",
    "    \n",
    "    def decompression (self, dataCompresse) :\n",
    "        return self.zip.decompress (dataCompresse)\n",
    "    \n",
    "    def initZip (self, zipChoisi = None ) :\n",
    "        if zipChoisi is None :\n",
    "            self.zip = rien()\n",
    "        else:\n",
    "            self.zip = self.dicoZip[zipChoisi]\n",
    "            \n",
    "    def create_index(self, index):\n",
    "        \"\"\"\n",
    "        creation de l' index si il n'existe pas.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.es.indices.exists(index=index):\n",
    "            self.es.indices.create(index=index)\n",
    "            \n",
    "    def delete_index(self, index):\n",
    "        \"\"\"\n",
    "        Supprime l'index, si il existe.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.es.indices.exists(index=  index):\n",
    "            self.es.indices.delete(index = index)\n",
    "            \n",
    "    def _docs (self, docIterator, index) :\n",
    "        dico = {'_index' : index,}\n",
    "        for doc in docIterator :\n",
    "            dico ['_source'] = doc\n",
    "            yield dico\n",
    "        return\n",
    "       \n",
    "    def bulk (self, docs, index,\n",
    "              isPurge_existing_index = False,\n",
    "              chunk_size = 2000,\n",
    "             ):\n",
    "        \"\"\"\n",
    "        \n",
    "        docs est un iterateur comme son nom ne l'indique pas\n",
    "        \n",
    "        \"\"\"\n",
    "        mapping = self.mapping\n",
    "        #print (\"mapping =\", mapping)\n",
    "        \n",
    "        if isPurge_existing_index:\n",
    "            self.delete_index(index) # si existe detruit\n",
    "            \n",
    "        self.create_index(index) # si existe ne fait rien\n",
    "        \n",
    "        if not mapping is None and isPurge_existing_index:\n",
    "            print (\"mapping =\", mapping)\n",
    "            self.es.indices.put_mapping(index = index, body = mapping)\n",
    "        \n",
    "        self.es.indices.put_settings({\"index\": {\"refresh_interval\": \"-1\"}},\n",
    "                                    index= index)\n",
    "\n",
    "        bulk(self.es, self._docs (docs, index) , chunk_size = chunk_size,\n",
    "                  raise_on_error=self.raise_on_error) # en cas d'erreur on renvoie False\n",
    "\n",
    "        self.es.indices.put_settings({\"index\": {\"refresh_interval\": \"1s\"}},\n",
    "                                         index = index)\n",
    "        self.es.indices.refresh()\n",
    "        \n",
    "        return True # tout est OK \n",
    "    \n",
    "    def count (self, index) :\n",
    "        if not self.es.indices.exists(index=  index):\n",
    "            return 0\n",
    "        \n",
    "        self.es.indices.refresh(index)\n",
    "        r = self.es.cat.count(index, params={\"format\": \"json\"})\n",
    "        return int (r [0] ['count'])\n",
    "    \n",
    "    # exemple de query sur les mots pour trouver les lemmes\n",
    "    def search_mot (self, index, mot, zone) :\n",
    "        self.es.indices.refresh (index)\n",
    "        query = {'query' : {'match' : {zone : mot}}}\n",
    "        #print (\"query =\", query )\n",
    "        res= self.es.search (index= index, body = query )\n",
    "        #res = self.elastic.search(index=index , body={\"query\": {\"match_all\": {}}})\n",
    "        #print ([hit['_source'] for hit in res ['hits'] ['hits']])\n",
    "        return [hit['_source'] for hit in res ['hits'] ['hits']]\n",
    "    \n",
    "    def creationDoc (self,origine, auteur, etape,  message,) :\n",
    "               \n",
    "        return {\"origine\": origine,\n",
    "               \"auteur\" : auteur,\n",
    "                \"etape\" : etape,\n",
    "                  \"date\" : datetime.now(),\n",
    "                   \"message\" : message, }\n",
    "        \n",
    "    \n",
    "    def log_error (self, auteur, etape,  message,) :\n",
    "        index = self.index_log_error\n",
    "        doc = self.creationDoc (\"error\", auteur, etape,  message,)\n",
    "        return self.index_doc (doc, index,)\n",
    "    \n",
    "    def log_warning (self, auteur, etape,  message,) :\n",
    "        index = self.index_log_warning\n",
    "        doc = self.creationDoc (\"warning\", auteur, etape,  message,)\n",
    "        return self.index_doc(doc, index,  )\n",
    "        \n",
    "    def log_trace (self, auteur, etape, message,  messagesStop = False) :\n",
    "        index = self.index_log_trace\n",
    "        doc = self.creationDoc (\"trace\", auteur, etape,  message,)\n",
    "        return self.index_doc (doc, index)\n",
    "        \n",
    "    def index_doc (self,doc, index, _id = None):\n",
    "        # on index l'erreur\n",
    "        if _id is None :\n",
    "            res = self.es.index (index = index, body = doc)\n",
    "        else :\n",
    "            res = self.es.index (index = index, id = _id, body = doc)\n",
    "        \n",
    "        self.es.indices.refresh()\n",
    "        #print ( \"dans ecriture erreur res =\", res['result'])\n",
    "        return True # tout est OK\n",
    "    \n",
    "    def get_date_system (self,) :\n",
    "        res = self.es.get(index=self.index_system, id=1)\n",
    "        #print(res['_source'])\n",
    "        doc = res['_source'] \n",
    "        return  doc ['date']\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def get_logs_error (self,) :\n",
    "        return self.get_logs(self.index_log_error)\n",
    "    def get_logs_warning (self,) :\n",
    "        return self.get_logs(self.index_log_warning)\n",
    "    def get_logs_trace(self,) :\n",
    "        return self.get_logs(self.index_log_trace)\n",
    "    \n",
    "    def get_logs (self, index, size = 10000) :\n",
    "        \n",
    "        self.es.indices.refresh (index)\n",
    "        \n",
    "        date_system = self.get_date_system ()\n",
    "        query = {'query' : {'range' : {\"date\": {\"gte\" : date_system}}} }\n",
    "        #print (\"query =\", query )\n",
    "        res= self.es.search (index= index, body = query,  size = size )\n",
    "        #res = self.elastic.search(index=index , body={\"query\": {\"match_all\": {}}})\n",
    "        #print ([hit['_source'] for hit in res ['hits'] ['hits']])\n",
    "        return [hit['_source'] for hit in res ['hits'] ['hits']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def search_par_bloc (self,index, ID, nom_variable,  ID_reference_min, ID_reference_max ,\n",
    "                        size = 10000 , isValeur = True, isID = False) :\n",
    "        \n",
    "        #modif ################################################\n",
    "        taille = len (self.ID_reference_base)\n",
    "        ID_reference_min_string  = (self.ID_reference_base + str(ID_reference_min) ) [-taille:]\n",
    "        ID_reference_max_string  = (self.ID_reference_base + str(ID_reference_max) ) [-taille:]\n",
    "        if isID :\n",
    "            query = {\"query\": {'bool': {'must': [ {\"match\": {\n",
    "                                                        \"nom_variable\":nom_variable, },\n",
    "                                         \n",
    "                                                },\n",
    "                                             {\"match\": {\n",
    "                                                      \"ID\":ID, },\n",
    "                                         \n",
    "                                                },\n",
    "                                            { \"range\" : {\n",
    "                                                    \"ID_reference\" : {\n",
    "                                                        \"gte\" :ID_reference_min_string,\n",
    "                                                        \"lt\" : ID_reference_max_string,\n",
    "                                                                    },\n",
    "                                                    },\n",
    "                                              },\n",
    "                                                ]\n",
    "                                        },},}\n",
    "        else :\n",
    "            query = {\"query\": {'bool': {'must': [ {\"match\": {\n",
    "                                      \"nom_variable\":nom_variable, },\n",
    "                                         \n",
    "                                                },\n",
    "                                             \n",
    "                                            { \"range\" : {\n",
    "                                                    \"ID_reference\" : {\n",
    "                                                        \"gte\" :ID_reference_min_string,\n",
    "                                                        \"lt\" : ID_reference_max_string,\n",
    "                                                                    },\n",
    "                                                    },\n",
    "                                              },]\n",
    "                                        },},}\n",
    "            \n",
    "        \n",
    "                \n",
    "            \n",
    "        #print (\"query =\", query)\n",
    "        \n",
    "        res = self.es.search (index= index, body = query , size = size)\n",
    "        hits = res['hits']\n",
    "        nombre= hits['total'] ['value']\n",
    "        vrai_hits= hits['hits']\n",
    "        if isValeur :\n",
    "            vrai_hits = [hit['_source'] ['valeur'] for hit in vrai_hits]\n",
    "        return nombre, vrai_hits\n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    ### search specialise ID et date_insertion\n",
    "    def close (self,) :\n",
    "        \n",
    "        self.es.indices.refresh()       \n",
    "        self.es.close()\n",
    "        \n",
    "        return\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-headline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convertible-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 = [ True  True  True  True  True  True  True  True  True  True]\n",
      "test2 = [ True  True  True  True  True  True  True  True  True  True]\n",
      "mapping = {'properties': {'ID': {'type': 'keyword'}, 'ID_reference': {'type': 'keyword'}, 'date_evenement': {'type': 'keyword'}, 'nom_variable': {'type': 'keyword'}, 'valeur': {'type': 'keyword'}}}\n",
      "bulk = True  en temps = 4.884499549865723\n",
      "\n",
      "\n",
      "[{'origine': 'error', 'auteur': 'test1', 'etape': 'etape1', 'date': '2021-03-03T18:08:49.510912', 'message': 'message1'}, {'origine': 'error', 'auteur': 'test1', 'etape': 'etape1', 'date': '2021-03-03T18:08:49.528104', 'message': 'message1'}]\n",
      "\n",
      "\n",
      "[{'origine': 'warning', 'auteur': 'test1', 'etape': 'etape1', 'date': '2021-03-03T18:08:49.543779', 'message': 'message1'}, {'origine': 'warning', 'auteur': 'test1', 'etape': 'etape1', 'date': '2021-03-03T18:08:49.563013', 'message': 'message1'}]\n",
      "\n",
      "\n",
      "[{'origine': 'trace', 'auteur': 'test1', 'etape': 'etape1', 'date': '2021-03-03T18:08:49.584888', 'message': 'message1'}, {'origine': 'trace', 'auteur': 'test1', 'etape': 'etape1', 'date': '2021-03-03T18:08:49.601118', 'message': 'message1'}]\n",
      "\n",
      " search pour 10000 valeurs realise en 0.10319900512695312\n",
      "\n",
      "search pour 10000 evenementsXvariables realise en 0.09457564353942871\n",
      "\n",
      "search pour 1 ID voulu sur 1000 evenements realise en 0.011188983917236328\n",
      "end of test\n"
     ]
    }
   ],
   "source": [
    "import json, time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from Kernel_BE import Kernel\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "system = {  \n",
    "          \"createur\" : \"generic\", \n",
    "          \"date_emetteur\" : str(datetime.now()),\n",
    "          \"http_auth\" : None,\n",
    "          \"timeout\" : 10,\n",
    "          \"host\" : \"localhost\", \n",
    "          \"port\" : 9200 ,\n",
    "          \"zipChoisi\" : 'bz2',\n",
    "          \"index_log_error\" : \"trace1\",\n",
    "          \"index_log_warning\" : \"trace2\",\n",
    "          \"index_log_trace\" : \"trace3\",\n",
    "          \"index_system\" : \"systeme\",\n",
    "          \"isPurge_existing_index_log\" : True,\n",
    "          \"extra_elasticsearch_args\" : None,\n",
    "          \"trace\" : False,\n",
    "          \"_ID_reference_base\" : \"000000000000000000000000000000\",\n",
    "    \n",
    "         \n",
    "                }\n",
    "\n",
    "ID_reference_base = \"000000000000000000000000000000\"\n",
    "k = Kernel(system)\n",
    "index = \"test\"\n",
    "k.create_index (index)\n",
    "k.delete_index (index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "array = np.array ([i for i in range(0, 10)])\n",
    "data = k.array2liste (array,)\n",
    "arrayF = k.liste2array( data,dtype = np.int32)\n",
    "\n",
    "print (\"test1 =\",array  == arrayF)\n",
    "\n",
    "array = np.array ([float(i)*0.1 for i in range(0, 10)])\n",
    "data = k.array2liste (array,)\n",
    "arrayF = k.liste2array( data,dtype = np.float64)\n",
    "\n",
    "print (\"test2 =\",array  == arrayF)\n",
    "#print (array)\n",
    "#print (arrayF)\n",
    "\n",
    "taille = len(ID_reference_base)\n",
    "def iterateur (kernel, nombre = 1000) :\n",
    "    \n",
    "    for i in range(0, nombre) :\n",
    "        for j in range(0,10) :\n",
    "            dico = {\n",
    "                  \"ID\" : str(i) ,\n",
    "                  \"date_evenement\" : (\"000000000\"+str(i))[-8:],\n",
    "                  \"ID_reference\" : (ID_reference_base  +str(i))[-taille:],\n",
    "                   \"nom_variable\" : \"variable_\"+ str(j),\n",
    "                   \"valeur\" : 1000000000000,\n",
    "            }\n",
    "            yield dico\n",
    "\n",
    "nombre = 10000    \n",
    "docs = iterateur (k, nombre = nombre)\n",
    "index = \"test\"\n",
    "\n",
    "t = time.time()\n",
    "k.bulk ( docs, index, isPurge_existing_index = True,)\n",
    "print (\"bulk =\",k.count (index) == nombre*10, \" en temps =\", time.time () - t)\n",
    "\n",
    "\n",
    "\n",
    "# on test les logs\n",
    "\n",
    "#auteur, etape,  message\n",
    "\n",
    "auteur = \"test1\"\n",
    "etape = \"etape1\"\n",
    "message = \"message1\"\n",
    "\n",
    "k.log_error (auteur, etape,  message)\n",
    "k.log_error (auteur, etape,  message)\n",
    "\n",
    "k.log_warning (auteur, etape,  message)\n",
    "k.log_warning (auteur, etape,  message)\n",
    "\n",
    "k.log_trace (auteur, etape,  message)\n",
    "k.log_trace (auteur, etape,  message)\n",
    "\n",
    "print ('\\n')\n",
    "print (k.get_logs_error())\n",
    "\n",
    "print ('\\n')\n",
    "print (k.get_logs_warning())\n",
    "\n",
    "print ('\\n')\n",
    "print (k.get_logs_trace())\n",
    "\n",
    "# test search bloc\n",
    "\n",
    "j = 5\n",
    "i = 0\n",
    "pas = 10000\n",
    "nom_variable = \"variable_\"+ str(j)\n",
    "ID_reference_min = i\n",
    "ID_reference_max = i + pas\n",
    "\n",
    "\n",
    "ID = str(i+2)\n",
    "\n",
    "index = \"test\"\n",
    "t = time.time()\n",
    "taille, hits = k.search_par_bloc (index,ID, nom_variable,  ID_reference_min, ID_reference_max,\n",
    "                                  size = pas,\n",
    "                                 isValeur = True)\n",
    "print ('\\n search pour 10000 valeurs realise en', time.time ()- t)\n",
    "if taille != len(hits) :\n",
    "    print ('erreur taille dans lecture de 1000 éléments')\n",
    "    \n",
    "t = time.time()\n",
    "taille, hits = k.search_par_bloc (index, ID, nom_variable,  ID_reference_min, ID_reference_max,\n",
    "                                  size = pas,\n",
    "                                 isValeur = False)\n",
    "print ('\\nsearch pour 10000 evenementsXvariables realise en', time.time ()- t)\n",
    "\n",
    "if taille != len(hits) :\n",
    "    print ('erreur taille de la data dans lecture de 1000 éléments')\n",
    "\n",
    "\n",
    "\n",
    "r = hits [0]['_source'] ['ID_reference']\n",
    "\n",
    "taille_1 = len(ID_reference_base)\n",
    "voulu = (ID_reference_base  +str (ID_reference_min))[-taille_1:]\n",
    "             \n",
    "if r != voulu :\n",
    "    print (\"erreur dans le contenu du premier hit\")\n",
    "    print (\"resultat =\",r)\n",
    "    print ('voulu =', voulu)\n",
    "    \n",
    "r = hits [taille - 1]['_source'] ['ID_reference']\n",
    "             \n",
    "taille_1 = len(ID_reference_base)             \n",
    "voulu = (ID_reference_base  +str(ID_reference_max-1))[-taille_1:]\n",
    "if r != voulu :\n",
    "    print (\"erreur dans le contenu du dernier hit\")\n",
    "    print (\"resultat =\",r)\n",
    "    print ('voulu =', voulu)\n",
    "    \n",
    "    \n",
    "# avec ID voulu\n",
    "j = 5\n",
    "i = 10\n",
    "pas = 10000\n",
    "\n",
    "ID = str(i)\n",
    "nom_variable = \"variable_\"+ str(j)\n",
    "ID_reference_min = i \n",
    "ID_reference_max = i + pas\n",
    "\n",
    "index = \"test\"\n",
    "t = time.time()\n",
    "taille, hits = k.search_par_bloc (index,ID, nom_variable,  ID_reference_min, ID_reference_max,\n",
    "                                  size = pas,\n",
    "                                  isValeur = False,\n",
    "                                  isID = True)\n",
    "\n",
    "print ('\\nsearch pour 1 ID voulu sur 1000 evenements realise en', time.time ()- t)\n",
    "\n",
    "    \n",
    "\n",
    "if (taille != len(hits)) or taille != 1 :\n",
    "    print ('erreur nombre d evenements pout cet ID')\n",
    "    \n",
    "    \n",
    "    \n",
    "# test lecture multiple de logs\n",
    "\n",
    "auteur = \"test1\"\n",
    "etape = \"etape1\"\n",
    "message = \"message1\"\n",
    "\n",
    "\n",
    "for i in range (0,10):\n",
    "    \n",
    "    k.log_error (auteur, etape,  message)\n",
    "    k.log_error (auteur, etape,  message)\n",
    "\n",
    "    k.log_warning (auteur, etape,  message)\n",
    "    k.log_warning (auteur, etape,  message)\n",
    "\n",
    "    k.log_trace (auteur, etape,  message)\n",
    "    k.log_trace (auteur, etape,  message)\n",
    "    \n",
    "    \n",
    "resultat = k.get_logs_trace ()\n",
    "if len(resultat) != 22 :\n",
    "    print ('erreur de lecture logs trace')\n",
    "    \n",
    "resultat = k.get_logs_warning ()\n",
    "if len(resultat) != 22 :\n",
    "    print ('erreur de lecture logs trace')\n",
    "    \n",
    "resultat = k.get_logs_error ()\n",
    "if len(resultat) != 22 :\n",
    "    print ('erreur de lecture logs trace')\n",
    "\n",
    "#print (len(resultat))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print ('end of test')    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-ferry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
